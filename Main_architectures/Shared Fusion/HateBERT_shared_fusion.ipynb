{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f2ba602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, Trainer, TrainingArguments, BartForConditionalGeneration\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from torch.optim import Adam\n",
    "from accelerate import Accelerator\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn \n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2bea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 14 11:24:50 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000               Off | 00000000:01:00.0 Off |                  Off |\n",
      "| 30%   28C    P8              15W / 230W |      3MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fe89323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "\n",
    "# meteor = load(\"meteor\")\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a97a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/dhruv/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnoel22338\u001b[0m (\u001b[33mnlp_project_team\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login --relogin --verify f59d448beb3315f3efbc5a0a80d9d2c346926308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ba515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('../Dataset/train.csv')\n",
    "testing_data = pd.read_csv('../Dataset/test.csv')\n",
    "validation_data = pd.read_csv('../Dataset/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edf54c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hatespeech', 'csType', 'counterspeech', 'Suggest', 'Relevance',\n",
      "       'Aggressive', 'Complexity', 'Comments', 'source', 'claim',\n",
      "       'centralTopic', 'speakerIntent', 'targetGroup', 'relevantPowerDynamics',\n",
      "       'hatespeechImplication', 'targetGroupEmotionalReaction',\n",
      "       'targetGroupCognitiveReaction', 'hatespeechOffensiveness', 'id',\n",
      "       'is_high_quality', 'hs_id', 'hatespeechTarget', 'powerDynamics',\n",
      "       'prompt_offensiveness', 'prompt_target_group', 'prompt_speaker_intent',\n",
      "       'prompt_power_dynamics', 'prompt_implication',\n",
      "       'prompt_emotional_reaction', 'prompt_cognitive_reaction',\n",
      "       'prompt_cs_generation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns = training_data.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af0e3b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialoGPTDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/hateBERT\")\n",
    "        self.bart_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "        # Intent label mapping\n",
    "        self.categories = {\n",
    "            'informative': 0,\n",
    "            'questioning': 1,\n",
    "            'denouncing': 2,\n",
    "            'positive': 3\n",
    "        }\n",
    "\n",
    "        # ✅ Create a mapping from hate speech → list of intent labels\n",
    "        self.intent_map = (\n",
    "            data.groupby(\"hatespeech\")[\"csType\"]\n",
    "            .apply(lambda x: [self.categories[t.lower()] for t in x.unique()])\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        # Tokenize hate speech\n",
    "        hate_inputs = self.tokenizer(\n",
    "            row[\"hatespeech\"],\n",
    "            return_tensors='pt',\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "        # Tokenize counterspeech\n",
    "        counter_inputs = self.bart_tokenizer(\n",
    "            row[\"counterspeech\"],\n",
    "            return_tensors='pt',\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "        intent_id = torch.tensor(self.categories[row[\"csType\"].lower()], dtype=torch.long)\n",
    "        all_intents = self.intent_map[row[\"hatespeech\"]]  # ✅ Look up all intents for this hate speech\n",
    "\n",
    "        return {\n",
    "            'input_ids': hate_inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': hate_inputs['attention_mask'].squeeze(0),\n",
    "            'counter_speech': counter_inputs['input_ids'].squeeze(0),\n",
    "            'intent_id': intent_id,\n",
    "            'raw_text': row[\"hatespeech\"],\n",
    "            'all_intents': all_intents  \n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
    "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
    "    counter_speech = torch.stack([item['counter_speech'] for item in batch])\n",
    "    intent_id = torch.stack([item['intent_id'] for item in batch])\n",
    "    all_intents = [item['all_intents'] for item in batch]\n",
    "    raw_inputs = [item['raw_text'] for item in batch]\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'counter_speech': counter_speech,\n",
    "        'intent_id': intent_id,\n",
    "        'all_intents': all_intents,\n",
    "        'raw_inputs':raw_inputs\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b35316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9532\n",
      "2971\n",
      "1470\n",
      "{'input_ids': tensor([  101,  2672,  1996,  4895,  2071,  2831,  2000,  2216,  4004,  1998,\n",
      "         3060,  3741,  3625,  2005,  3938,  1009,  1997,  1996, 10796,  1999,\n",
      "         1996, 17401,  2612,  1997, 22604,  2006,  2023, 14636,  2055,  4785,\n",
      "         2689,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'counter_speech': tensor([    0,   133,   201,    16,     5,   200,   144,  2902, 15024,   247,\n",
      "           11,     5,   232,   111,    25,     5,   232,    17,    27,    29,\n",
      "          934,  2683,     8,  1861,   476,     4,    52,    32,    70,     7,\n",
      "         4887,   259,     8,   240,     7,   173,   865,    11,   865,     7,\n",
      "         1045,  5068,   464,     6,    25,  4340,     7,  7547,     5,  8411,\n",
      "            7,   643,     4,     2,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1]), 'intent_id': tensor(0), 'raw_text': 'Maybe the UN could talk to those asian and african nations responsible for 90+ of the pollution in the oceans instead of insisting on this bullshit about climate change.', 'all_intents': [0, 1, 2, 3]}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DialoGPTDataset(training_data)\n",
    "test_dataset = DialoGPTDataset(testing_data)\n",
    "validation_dataset = DialoGPTDataset(validation_data)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(validation_dataset))\n",
    "\n",
    "print(train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "795e9f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, next_input):\n",
    "        super(FeatureEncoder, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained('GroNLP/hateBERT')\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_size = next_input\n",
    "\n",
    "        self.informative_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.questioning_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.denouncing_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.positive_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hate_speech_h = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        informative_e = self.informative_head(hate_speech_h)\n",
    "        questioning_e = self.questioning_head(hate_speech_h)\n",
    "        denouncing_e = self.denouncing_head(hate_speech_h)\n",
    "        positive_e = self.positive_head(hate_speech_h)\n",
    "\n",
    "        return informative_e, questioning_e, denouncing_e, positive_e, hate_speech_h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46dbb3",
   "metadata": {},
   "source": [
    "### SharedFusion Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfc44d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedFusionMechanism(torch.nn.Module):\n",
    "    def __init__(self, hate_speech_dim, intent_dim, output_dim, num_heads=4):\n",
    "        super(SharedFusionMechanism, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        # First, project both embeddings to the same dimension\n",
    "        self.common_dim = 512  # Choose a suitable common dimension\n",
    "        self.hse_projection = torch.nn.Linear(hate_speech_dim, self.common_dim)\n",
    "        self.ie_projection = torch.nn.Linear(intent_dim, self.common_dim)\n",
    "        \n",
    "        # Multi-head attention components for cross attention\n",
    "        self.head_dim = self.common_dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "        # Attention projections for hate speech embedding as query\n",
    "        self.q_hse = torch.nn.Linear(self.common_dim, self.common_dim)\n",
    "        self.k_ie = torch.nn.Linear(self.common_dim, self.common_dim)\n",
    "        self.v_ie = torch.nn.Linear(self.common_dim, self.common_dim)\n",
    "        \n",
    "        # Attention projections for intent embedding as query\n",
    "        self.q_ie = torch.nn.Linear(self.common_dim, self.common_dim)\n",
    "        self.k_hse = torch.nn.Linear(self.common_dim, self.common_dim)\n",
    "        self.v_hse = torch.nn.Linear(self.common_dim, self.common_dim)\n",
    "        \n",
    "        # Gating mechanisms\n",
    "        self.gate_hse = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.common_dim, self.common_dim),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.gate_ie = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.common_dim, self.common_dim),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Learnable weighting parameters for fusion\n",
    "        self.alpha_1 = torch.nn.Parameter(torch.tensor(0.25))\n",
    "        self.alpha_2 = torch.nn.Parameter(torch.tensor(0.25))\n",
    "        self.beta_1 = torch.nn.Parameter(torch.tensor(0.25))\n",
    "        self.beta_2 = torch.nn.Parameter(torch.tensor(0.25))\n",
    "        \n",
    "        # Final projection to output dimension\n",
    "        self.output_projection = torch.nn.Linear(self.common_dim, output_dim)\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.layer_norm = torch.nn.LayerNorm(self.common_dim)\n",
    "        \n",
    "    def compute_attention(self, q, k, v):\n",
    "        \"\"\"Compute multi-head attention\"\"\"\n",
    "        # Reshape for multi-head attention\n",
    "        batch_size = q.shape[0]\n",
    "        q = q.view(batch_size, self.num_heads, self.head_dim)\n",
    "        k = k.view(batch_size, self.num_heads, self.head_dim)\n",
    "        v = v.view(batch_size, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Reshape for attention computation (adding sequence length dimension of 1)\n",
    "        q = q.unsqueeze(2)  # [batch_size, num_heads, 1, head_dim]\n",
    "        k = k.unsqueeze(2)  # [batch_size, num_heads, 1, head_dim]\n",
    "        v = v.unsqueeze(2)  # [batch_size, num_heads, 1, head_dim]\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attention_scores = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "        attention_weights = torch.nn.functional.softmax(attention_scores, dim=-1)\n",
    "        \n",
    "        # Apply attention weights to values\n",
    "        context = torch.matmul(attention_weights, v)  # [batch_size, num_heads, 1, head_dim]\n",
    "        context = context.squeeze(2).view(batch_size, -1)  # [batch_size, common_dim]\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def forward(self, hate_speech_h, intent_e):\n",
    "        \"\"\"\n",
    "        hate_speech_h: hate speech embedding [batch_size or single, hate_speech_dim]\n",
    "        intent_e: intent embedding [batch_size or single, intent_dim]\n",
    "        \"\"\"\n",
    "        # Add batch dimension if not present\n",
    "        if hate_speech_h.dim() == 1:\n",
    "            hate_speech_h = hate_speech_h.unsqueeze(0)  # [1, hate_speech_dim]\n",
    "        if intent_e.dim() == 1:\n",
    "            intent_e = intent_e.unsqueeze(0)  # [1, intent_dim]\n",
    "            \n",
    "        batch_size = hate_speech_h.shape[0]\n",
    "        \n",
    "        # Project to common dimension\n",
    "        E_hse = self.hse_projection(hate_speech_h)  # [batch_size, common_dim]\n",
    "        E_ie = self.ie_projection(intent_e)         # [batch_size, common_dim]\n",
    "        \n",
    "        # Apply multi-head attention\n",
    "        # Hate speech as query, intent as key/value\n",
    "        q_hse = self.q_hse(E_hse)\n",
    "        k_ie = self.k_ie(E_ie)\n",
    "        v_ie = self.v_ie(E_ie)\n",
    "        A_ie = self.compute_attention(q_hse, k_ie, v_ie)\n",
    "        \n",
    "        # Intent as query, hate speech as key/value\n",
    "        q_ie = self.q_ie(E_ie)\n",
    "        k_hse = self.k_hse(E_hse)\n",
    "        v_hse = self.v_hse(E_hse)\n",
    "        A_hse = self.compute_attention(q_ie, k_hse, v_hse)\n",
    "        \n",
    "        # Cross embeddings with attention\n",
    "        F_hse_ei = A_ie * E_hse  # [batch_size, common_dim]\n",
    "        F_ei_hse = A_hse * E_ie  # [batch_size, common_dim]\n",
    "        \n",
    "        # Compute gates\n",
    "        G_hse = self.gate_hse(E_hse)  # [batch_size, common_dim]\n",
    "        G_ie = self.gate_ie(E_ie)     # [batch_size, common_dim]\n",
    "        \n",
    "        # Fusing the multimodal representations\n",
    "        F_1 = (G_hse * F_hse_ei) + ((1 - G_hse) * F_ei_hse)  # [batch_size, common_dim]\n",
    "        F_2 = (G_ie * F_hse_ei) + ((1 - G_ie) * F_ei_hse)    # [batch_size, common_dim]\n",
    "        \n",
    "        # Cross modal fusion\n",
    "        F_hse = (G_hse * E_hse) + ((1 - G_hse) * F_hse_ei)  # [batch_size, common_dim]\n",
    "        F_ei = (G_ie * E_ie) + ((1 - G_ie) * F_ei_hse)      # [batch_size, common_dim]\n",
    "        \n",
    "        # Final shared fusion with learnable parameters\n",
    "        F_sf = (self.alpha_1 * F_1) + (self.alpha_2 * F_2) + (self.beta_1 * F_hse) + (self.beta_2 * F_ei)\n",
    "        \n",
    "        # Layer normalization\n",
    "        F_sf = self.layer_norm(F_sf)\n",
    "        \n",
    "        # Project to output dimension\n",
    "        output = self.output_projection(F_sf)\n",
    "        \n",
    "        # Remove batch dimension if it was added\n",
    "        if hate_speech_h.shape[0] == 1 and intent_e.shape[0] == 1:\n",
    "            output = output.squeeze(0)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d49cc606",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CounterSpeechNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, encoder_output, max_length):\n",
    "        super(CounterSpeechNetwork, self).__init__()\n",
    "\n",
    "        self.feature_encoder = FeatureEncoder(input_dim, hidden_dim, encoder_output)\n",
    "\n",
    "        self.informative_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "        self.questioning_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "        self.denouncing_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "        self.positive_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "\n",
    "        bart_dim = self.informative_decoder.config.d_model\n",
    "        \n",
    "        # Use the shared fusion mechanism\n",
    "        self.shared_fusion = SharedFusionMechanism(hidden_dim, encoder_output, bart_dim)\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, intent_id, counter_speech=None):\n",
    "        informative_e, questioning_e, denouncing_e, positive_e, hate_speech_h = self.feature_encoder(input_ids, attention_mask)\n",
    "\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        fused = torch.zeros(batch_size, 1, self.informative_decoder.config.d_model, device=input_ids.device)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # Get the appropriate intent embedding based on intent_id\n",
    "            if intent_id[i] == 0:\n",
    "                intent_e = informative_e[i]\n",
    "            elif intent_id[i] == 1:\n",
    "                intent_e = questioning_e[i]\n",
    "            elif intent_id[i] == 2:\n",
    "                intent_e = denouncing_e[i]\n",
    "            elif intent_id[i] == 3:\n",
    "                intent_e = positive_e[i]\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid intent_id: {intent_id[i]}\")\n",
    "                \n",
    "            # Use the shared fusion mechanism\n",
    "            fused[i] = self.shared_fusion(hate_speech_h[i], intent_e).unsqueeze(0)\n",
    "\n",
    "        # The rest of your forward method remains unchanged\n",
    "        if counter_speech is not None:\n",
    "            losses = []\n",
    "            for i in range(batch_size):\n",
    "                if intent_id[i] == 0:\n",
    "                    output = self.informative_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
    "                elif intent_id[i] == 1:\n",
    "                    output = self.questioning_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
    "                elif intent_id[i] == 2:\n",
    "                    output = self.denouncing_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
    "                elif intent_id[i] == 3:\n",
    "                    output = self.positive_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
    "                losses.append(output.loss)\n",
    "            avg_loss = sum(losses) / len(losses)  # Average loss across the batch\n",
    "            return None, avg_loss  # No decoded text during training\n",
    "        else:\n",
    "            decoded_texts = []\n",
    "            for i in range(batch_size):\n",
    "                if intent_id[i] == 0:\n",
    "                    output = self.informative_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
    "                elif intent_id[i] == 1:\n",
    "                    output = self.questioning_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
    "                elif intent_id[i] == 2:\n",
    "                    output = self.denouncing_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
    "                elif intent_id[i] == 3:\n",
    "                    output = self.positive_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
    "                decoded_texts.append(self.tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "            return decoded_texts, None  # Decoded text during inference, no loss\n",
    "        \n",
    "    def judge_responses(self,input_ids, attention_mask,counter_speech=None):\n",
    "        \n",
    "        informative_e, questioning_e, denouncing_e, positive_e, hate_speech_h = self.feature_encoder(input_ids, attention_mask)\n",
    "\n",
    "        batch_size = input_ids.size(0)\n",
    "        output_dict = {'informative':[],'questioning':[],'denouncing':[],'positive':[]}\n",
    "        informative_fused = torch.zeros(batch_size, 1, self.informative_decoder.config.d_model, device=input_ids.device)\n",
    "        questioning_fused = torch.zeros(batch_size, 1, self.informative_decoder.config.d_model, device=input_ids.device)\n",
    "        denouncing_fused = torch.zeros(batch_size, 1, self.informative_decoder.config.d_model, device=input_ids.device)\n",
    "        positive_fused = torch.zeros(batch_size, 1, self.informative_decoder.config.d_model, device=input_ids.device)\n",
    "        \n",
    "    \n",
    "        for i in range(batch_size):\n",
    "            informative_fused[i] = self.shared_fusion( hate_speech_h[i], informative_e[i]).unsqueeze(0)\n",
    "            questioning_fused[i] = self.shared_fusion( hate_speech_h[i], questioning_e[i]).unsqueeze(0)\n",
    "            denouncing_fused[i] = self.shared_fusion(hate_speech_h[i], denouncing_e[i]).unsqueeze(0)\n",
    "            positive_fused[i] = self.shared_fusion(hate_speech_h[i] , positive_e[i]).unsqueeze(0)\n",
    "\n",
    "            output_dict['informative'].append(self.informative_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=informative_fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0)))\n",
    "            output_dict['questioning'].append(self.questioning_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=questioning_fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0)))\n",
    "            output_dict['denouncing'].append(self.denouncing_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=denouncing_fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0)))\n",
    "            output_dict['positive'].append(self.positive_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=positive_fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0)))\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47c15eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 3.4210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Validation Loss: 1.4276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.9777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Validation Loss: 0.7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.7724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Validation Loss: 0.7061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.6959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Validation Loss: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.6380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Validation Loss: 0.6834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.6438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Validation Loss: 0.7101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.5549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Validation Loss: 0.6893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.5080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Validation Loss: 0.6969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.4683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Validation Loss: 0.6995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Validation Loss: 0.7186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model = CounterSpeechNetwork(input_dim=128, hidden_dim=768, encoder_output=256, max_length=50)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn= custom_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "\n",
    "    # Wrap train_dataloader with tqdm for training progress\n",
    "    train_loop = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs} [Train]\", leave=False)\n",
    "    for batch in train_loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        counter_speech = batch['counter_speech'].to(device)\n",
    "        intent_ids = batch['intent_id'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Process the entire batch at once\n",
    "        _, loss = model(input_ids, attention_mask, intent_ids, counter_speech)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Update tqdm with current batch loss\n",
    "        train_loop.set_postfix({'batch_loss': loss.item(), 'avg_loss': total_train_loss / (train_loop.n + 1)})\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} | Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    # Wrap validation_dataloader with tqdm for validation progress\n",
    "    val_loop = tqdm(validation_dataloader, desc=f\"Epoch {epoch + 1}/{epochs} [Validation]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loop:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            counter_speech = batch['counter_speech'].to(device)\n",
    "            intent_ids = batch['intent_id'].to(device)\n",
    "\n",
    "            # Process the entire batch at once\n",
    "            _, loss = model(input_ids, attention_mask, intent_ids, counter_speech)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # Update tqdm with current batch loss\n",
    "            val_loop.set_postfix({'batch_loss': loss.item(), 'avg_loss': total_val_loss / (val_loop.n + 1)})\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(validation_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} | Validation Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ca125a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'HateBERT_shared_fusion_final.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d076f3",
   "metadata": {},
   "source": [
    "### Evaluation Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e437f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DialoGPTDataset(testing_data)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d755976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_judge_model(model, test_dataloader, device):\n",
    "    categories = {\n",
    "        'informative': 0,\n",
    "        'questioning': 1,\n",
    "        'denouncing': 2,\n",
    "        'positive': 3\n",
    "    }\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "    judge_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
    "    judge_model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-small\").to(device)\n",
    "    judge_model.eval()\n",
    "    print(\"Judge model ready!\")\n",
    "\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    test_loop = tqdm(test_dataloader, desc=\"Test Evaluation\", leave=True)\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loop:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            counter_speech = batch['counter_speech'].to(device)\n",
    "            raw_inputs = batch['raw_inputs']\n",
    "            all_intents = batch['all_intents']  # list of gold intents per sample (as int indices)\n",
    "\n",
    "            outputs = model.judge_responses(input_ids, attention_mask, counter_speech)\n",
    "\n",
    "            for i in range(len(input_ids)):\n",
    "                intent_scores = {}\n",
    "\n",
    "                for intent in [\"informative\", \"questioning\", \"denouncing\", \"positive\"]:\n",
    "                    response = model.tokenizer.decode(\n",
    "                        torch.argmax(outputs[intent][i].logits, dim=-1)[0],\n",
    "                        skip_special_tokens=True\n",
    "                    )\n",
    "\n",
    "                    # Prompting for a rating\n",
    "                    prompt = (\n",
    "                        f\"Hate speech: {raw_inputs[i]}\\n\"\n",
    "                        f\"Proposed counterspeech (intent: {intent}): {response}\\n\\n\"\n",
    "                        f\"On a scale of 1 to 10, how appropriate and effective is this counterspeech in response to the hate speech? Just respond with a number.\"\n",
    "                    )\n",
    "\n",
    "                    judge_input = judge_tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "                    output_ids = judge_model.generate(judge_input, max_new_tokens=10, pad_token_id=judge_tokenizer.eos_token_id)\n",
    "                    score_text = judge_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "                    try:\n",
    "                        # Extract the first number in response (robust to \"I would give it a 7\" etc.)\n",
    "                        score = next((float(s) for s in score_text.split() if s.replace('.', '', 1).isdigit()), 0)\n",
    "                        score = max(0, min(score, 10))  # Clamp between 0 and 10\n",
    "                    except:\n",
    "                        score = 0  # Fallback score if judge LM fails\n",
    "\n",
    "                    intent_scores[intent] = score\n",
    "\n",
    "                # Pick best scoring intent\n",
    "                best_intent = max(intent_scores, key=intent_scores.get)\n",
    "                best_intent_idx = categories[best_intent]\n",
    "\n",
    "                if best_intent_idx in all_intents[i]:\n",
    "                    correct_predictions += 1\n",
    "                total_samples += 1\n",
    "\n",
    "            test_loop.set_postfix({'accuracy': correct_predictions / total_samples if total_samples else 0})\n",
    "\n",
    "    final_accuracy = correct_predictions / total_samples if total_samples else 0\n",
    "    return final_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a83c412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/dhruv/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/dhruv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/tmp/ipykernel_1509112/3285358310.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"HateBERT_shared_fusion_final.pth\", map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
      "Test Evaluation:   0%|          | 0/93 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Test Evaluation: 100%|██████████| 93/93 [10:29<00:00,  6.77s/it]\n"
     ]
    }
   ],
   "source": [
    "# Download required data for METEOR\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize model\n",
    "model = CounterSpeechNetwork(input_dim=128, hidden_dim=768, encoder_output=256, max_length=50)\n",
    "model.load_state_dict(torch.load(\"HateBERT_shared_fusion_final.pth\", map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Evaluation loop\n",
    "test_predictions = []\n",
    "test_references = []\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "meteor_scores = []\n",
    "cosine_sims = []\n",
    "\n",
    "test_loop = tqdm(test_dataloader, desc=\"Test Evaluation\", leave=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        counter_speech = batch['counter_speech'].to(device)  # Reference texts\n",
    "        intent_ids = batch['intent_id'].to(device)\n",
    "\n",
    "        predictions, logits = model(input_ids, attention_mask, intent_ids)\n",
    "        \n",
    "        # Decode predictions and references\n",
    "        pred_texts = predictions\n",
    "        ref_texts = [model.tokenizer.decode(cs, skip_special_tokens=True) for cs in counter_speech]\n",
    "\n",
    "        test_predictions.extend(pred_texts)\n",
    "        test_references.extend(ref_texts)\n",
    "\n",
    "        # Compute METEOR and Cosine Similarity\n",
    "        for pred, ref in zip(pred_texts, ref_texts):\n",
    "            score = meteor_score([ref.split()], pred.split())\n",
    "            meteor_scores.append(score)\n",
    "\n",
    "            # Cosine similarity using simple TF representation\n",
    "            pred_vec = model.tokenizer(pred, return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].float()\n",
    "            ref_vec = model.tokenizer(ref, return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].float()\n",
    "\n",
    "            pred_vec = normalize(torch.sum(pred_vec, dim=1).numpy().reshape(1, -1))\n",
    "            ref_vec = normalize(torch.sum(ref_vec, dim=1).numpy().reshape(1, -1))\n",
    "            cos_sim = cosine_similarity(pred_vec, ref_vec)[0][0]\n",
    "            cosine_sims.append(cos_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67382e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47cce59ff8c4acea0a93dd56ef5c9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d635934c5d954131acd0827532189e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 9.60 seconds, 309.51 sentences/sec\n",
      "Judge model ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Evaluation:   0%|          | 0/93 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Test Evaluation: 100%|██████████| 93/93 [05:27<00:00,  3.52s/it, accuracy=0.751]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Metrics ===\n",
      "Total Predictions: 2971\n",
      "BERTScore - Precision: 0.8714, Recall: 0.8703, F1: 0.8707\n",
      "ROUGE - Rouge-1: 0.2505, Rouge-2: 0.0647, Rouge-L: 0.1759\n",
      "METEOR: 0.1578\n",
      "Cosine Similarity: 1.0000\n",
      "Category Accuracy (Intent): 0.7513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute BERTScore\n",
    "P, R, F1 = bert_score(test_predictions, test_references, lang=\"en\", verbose=True)\n",
    "\n",
    "# Compute ROUGE\n",
    "rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "for pred, ref in zip(test_predictions, test_references):\n",
    "    scores = scorer.score(ref, pred)\n",
    "    rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n",
    "    rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n",
    "    rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n",
    "\n",
    "avg_rouge1 = sum(rouge_scores['rouge1']) / len(rouge_scores['rouge1'])\n",
    "avg_rouge2 = sum(rouge_scores['rouge2']) / len(rouge_scores['rouge2'])\n",
    "avg_rougeL = sum(rouge_scores['rougeL']) / len(rouge_scores['rougeL'])\n",
    "avg_meteor = sum(meteor_scores) / len(meteor_scores)\n",
    "avg_cosine = sum(cosine_sims) / len(cosine_sims)\n",
    "\n",
    "# Compute category (intent) accuracy\n",
    "intent_accuracy = evaluate_with_judge_model(model,test_dataloader,device)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n=== Evaluation Metrics ===\")\n",
    "print(f\"Total Predictions: {len(test_predictions)}\")\n",
    "print(f\"BERTScore - Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")\n",
    "print(f\"ROUGE - Rouge-1: {avg_rouge1:.4f}, Rouge-2: {avg_rouge2:.4f}, Rouge-L: {avg_rougeL:.4f}\")\n",
    "print(f\"METEOR: {avg_meteor:.4f}\")\n",
    "print(f\"Cosine Similarity: {avg_cosine:.4f}\")\n",
    "print(f\"Category Accuracy (Intent): {intent_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3722cd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Saved predictions to predictions_HateBERT-shared-fusion.txt\n"
     ]
    }
   ],
   "source": [
    "# Save test predictions to a text file\n",
    "model_name = \"HateBERT-shared-fusion\"\n",
    "txt_filename = f\"predictions_{model_name}.txt\"\n",
    "with open(txt_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    for pred in test_predictions:\n",
    "        f.write(pred.strip() + \"\\n\")\n",
    "\n",
    "print(f\"📄 Saved predictions to {txt_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_project)",
   "language": "python",
   "name": "nlp_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
