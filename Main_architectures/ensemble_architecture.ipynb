{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "QJ-yxJ6P_6dU",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, Trainer, TrainingArguments, BartForConditionalGeneration\n",
        "from transformers.modeling_outputs import BaseModelOutput\n",
        "from torch.optim import Adam\n",
        "from accelerate import Accelerator\n",
        "import wandb\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239,
          "referenced_widgets": [
            "36aff3cc8ee845b08abd7f18589726fa",
            "f5df75b26d1d464fb722dff990b5476a",
            "00606f57d8884a8da09c02a2b181667c",
            "5ae640fb971841d9b86737e6fd0b4c78",
            "452dc6a25a544daab3217fae74b699e9",
            "fccb872427ac46018921c52b405210ea",
            "1274c2be26b64ab3b4ac358f7606a310",
            "baa6a137ee63491cb9a5f54e44095154",
            "13cfef767914493fb7c16b42845c4c45",
            "95abeb3513704f59b66711a516c6130a",
            "4d09db8336c340e4be9bc537537f4b0d"
          ]
        },
        "id": "vTDocM7nI_Hw",
        "outputId": "f3d7a035-b43f-46dc-d8e4-166f70fc7b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36aff3cc8ee845b08abd7f18589726fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "from evaluate import load\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import score as bert_score\n",
        "\n",
        "meteor = load(\"meteor\")\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eLC8QX4qI_Hw"
      },
      "outputs": [],
      "source": [
        "accelerator = Accelerator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj0qY8zOI_Hx",
        "outputId": "087c651e-4068-420a-a242-4f2ba44c48ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnoel22338\u001b[0m (\u001b[33mnlp_project_team\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login --relogin --verify ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "B6MBEOJg_6dV"
      },
      "outputs": [],
      "source": [
        "training_data = pd.read_csv('train.csv')\n",
        "testing_data = pd.read_csv('test.csv')\n",
        "validation_data = pd.read_csv('validation.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "KPdXrxQg_6dW",
        "outputId": "da88817b-93ac-4215-bfa8-7c8849baf2dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          hatespeech       csType  \\\n",
              "0  Maybe the UN could talk to those asian and afr...  Informative   \n",
              "1  Maybe the UN could talk to those asian and afr...  Questioning   \n",
              "2  Maybe the UN could talk to those asian and afr...   Denouncing   \n",
              "3  Maybe the UN could talk to those asian and afr...     Positive   \n",
              "4  Juice Jews are worse that nukes. Caption to a ...  Informative   \n",
              "\n",
              "                                       counterspeech Suggest  Relevance  \\\n",
              "0  The us is the second most polluting country in...       3        4.0   \n",
              "1  Doesn't everyone on the planet have a responsi...                3.0   \n",
              "2  The world would be a better place if people we...       1        1.0   \n",
              "3  You're right, ocean pollution is one of the ma...       3        4.0   \n",
              "4  Anti-semitism is a serious problem that we nee...       2        3.0   \n",
              "\n",
              "   Aggressive  Complexity  Comments source  \\\n",
              "0         2.0         3.0       NaN  Human   \n",
              "1         2.0         2.0       NaN  Human   \n",
              "2         2.0         2.0       NaN  Human   \n",
              "3         2.0         2.0       NaN  Human   \n",
              "4         2.0         2.0       NaN  Human   \n",
              "\n",
              "                                               claim  ... hatespeechTarget  \\\n",
              "0  The UN should focus on Asian and African natio...  ...     asian_people   \n",
              "1  The UN should focus on Asian and African natio...  ...     asian_people   \n",
              "2  The UN should focus on Asian and African natio...  ...     asian_people   \n",
              "3  The UN should focus on Asian and African natio...  ...     asian_people   \n",
              "4                         Jews are worse than nukes.  ...             jews   \n",
              "\n",
              "  powerDynamics                               prompt_offensiveness  \\\n",
              "0        racial  Analyze the offensiveness of the statement: Ma...   \n",
              "1        racial  Analyze the offensiveness of the statement: Ma...   \n",
              "2        racial  Analyze the offensiveness of the statement: Ma...   \n",
              "3        racial  Analyze the offensiveness of the statement: Ma...   \n",
              "4      religion  Analyze the offensiveness of the statement: Ju...   \n",
              "\n",
              "                                 prompt_target_group  \\\n",
              "0  Identify the group of people that the speaker ...   \n",
              "1  Identify the group of people that the speaker ...   \n",
              "2  Identify the group of people that the speaker ...   \n",
              "3  Identify the group of people that the speaker ...   \n",
              "4  Identify the group of people that the speaker ...   \n",
              "\n",
              "                               prompt_speaker_intent  \\\n",
              "0  Analyze the speaker's intention behind writing...   \n",
              "1  Analyze the speaker's intention behind writing...   \n",
              "2  Analyze the speaker's intention behind writing...   \n",
              "3  Analyze the speaker's intention behind writing...   \n",
              "4  Analyze the speaker's intention behind writing...   \n",
              "\n",
              "                               prompt_power_dynamics  \\\n",
              "0  Explain the underlying power dynamics between ...   \n",
              "1  Explain the underlying power dynamics between ...   \n",
              "2  Explain the underlying power dynamics between ...   \n",
              "3  Explain the underlying power dynamics between ...   \n",
              "4  Explain the underlying power dynamics between ...   \n",
              "\n",
              "                                  prompt_implication  \\\n",
              "0  Explain the implied meaning underlying the off...   \n",
              "1  Explain the implied meaning underlying the off...   \n",
              "2  Explain the implied meaning underlying the off...   \n",
              "3  Explain the implied meaning underlying the off...   \n",
              "4  Explain the implied meaning underlying the off...   \n",
              "\n",
              "                           prompt_emotional_reaction  \\\n",
              "0  Describe how the target group might feel emoti...   \n",
              "1  Describe how the target group might feel emoti...   \n",
              "2  Describe how the target group might feel emoti...   \n",
              "3  Describe how the target group might feel emoti...   \n",
              "4  Describe how the target group might feel emoti...   \n",
              "\n",
              "                           prompt_cognitive_reaction  \\\n",
              "0  Describe how the target group might react cogn...   \n",
              "1  Describe how the target group might react cogn...   \n",
              "2  Describe how the target group might react cogn...   \n",
              "3  Describe how the target group might react cogn...   \n",
              "4  Describe how the target group might react cogn...   \n",
              "\n",
              "                                prompt_cs_generation  \n",
              "0  Analyze the different aspects such as offensiv...  \n",
              "1  Analyze the different aspects such as offensiv...  \n",
              "2  Analyze the different aspects such as offensiv...  \n",
              "3  Analyze the different aspects such as offensiv...  \n",
              "4  Analyze the different aspects such as offensiv...  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e571890-70a1-4b2c-a52e-809c4904074d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hatespeech</th>\n",
              "      <th>csType</th>\n",
              "      <th>counterspeech</th>\n",
              "      <th>Suggest</th>\n",
              "      <th>Relevance</th>\n",
              "      <th>Aggressive</th>\n",
              "      <th>Complexity</th>\n",
              "      <th>Comments</th>\n",
              "      <th>source</th>\n",
              "      <th>claim</th>\n",
              "      <th>...</th>\n",
              "      <th>hatespeechTarget</th>\n",
              "      <th>powerDynamics</th>\n",
              "      <th>prompt_offensiveness</th>\n",
              "      <th>prompt_target_group</th>\n",
              "      <th>prompt_speaker_intent</th>\n",
              "      <th>prompt_power_dynamics</th>\n",
              "      <th>prompt_implication</th>\n",
              "      <th>prompt_emotional_reaction</th>\n",
              "      <th>prompt_cognitive_reaction</th>\n",
              "      <th>prompt_cs_generation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Maybe the UN could talk to those asian and afr...</td>\n",
              "      <td>Informative</td>\n",
              "      <td>The us is the second most polluting country in...</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Human</td>\n",
              "      <td>The UN should focus on Asian and African natio...</td>\n",
              "      <td>...</td>\n",
              "      <td>asian_people</td>\n",
              "      <td>racial</td>\n",
              "      <td>Analyze the offensiveness of the statement: Ma...</td>\n",
              "      <td>Identify the group of people that the speaker ...</td>\n",
              "      <td>Analyze the speaker's intention behind writing...</td>\n",
              "      <td>Explain the underlying power dynamics between ...</td>\n",
              "      <td>Explain the implied meaning underlying the off...</td>\n",
              "      <td>Describe how the target group might feel emoti...</td>\n",
              "      <td>Describe how the target group might react cogn...</td>\n",
              "      <td>Analyze the different aspects such as offensiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Maybe the UN could talk to those asian and afr...</td>\n",
              "      <td>Questioning</td>\n",
              "      <td>Doesn't everyone on the planet have a responsi...</td>\n",
              "      <td></td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Human</td>\n",
              "      <td>The UN should focus on Asian and African natio...</td>\n",
              "      <td>...</td>\n",
              "      <td>asian_people</td>\n",
              "      <td>racial</td>\n",
              "      <td>Analyze the offensiveness of the statement: Ma...</td>\n",
              "      <td>Identify the group of people that the speaker ...</td>\n",
              "      <td>Analyze the speaker's intention behind writing...</td>\n",
              "      <td>Explain the underlying power dynamics between ...</td>\n",
              "      <td>Explain the implied meaning underlying the off...</td>\n",
              "      <td>Describe how the target group might feel emoti...</td>\n",
              "      <td>Describe how the target group might react cogn...</td>\n",
              "      <td>Analyze the different aspects such as offensiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Maybe the UN could talk to those asian and afr...</td>\n",
              "      <td>Denouncing</td>\n",
              "      <td>The world would be a better place if people we...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Human</td>\n",
              "      <td>The UN should focus on Asian and African natio...</td>\n",
              "      <td>...</td>\n",
              "      <td>asian_people</td>\n",
              "      <td>racial</td>\n",
              "      <td>Analyze the offensiveness of the statement: Ma...</td>\n",
              "      <td>Identify the group of people that the speaker ...</td>\n",
              "      <td>Analyze the speaker's intention behind writing...</td>\n",
              "      <td>Explain the underlying power dynamics between ...</td>\n",
              "      <td>Explain the implied meaning underlying the off...</td>\n",
              "      <td>Describe how the target group might feel emoti...</td>\n",
              "      <td>Describe how the target group might react cogn...</td>\n",
              "      <td>Analyze the different aspects such as offensiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Maybe the UN could talk to those asian and afr...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>You're right, ocean pollution is one of the ma...</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Human</td>\n",
              "      <td>The UN should focus on Asian and African natio...</td>\n",
              "      <td>...</td>\n",
              "      <td>asian_people</td>\n",
              "      <td>racial</td>\n",
              "      <td>Analyze the offensiveness of the statement: Ma...</td>\n",
              "      <td>Identify the group of people that the speaker ...</td>\n",
              "      <td>Analyze the speaker's intention behind writing...</td>\n",
              "      <td>Explain the underlying power dynamics between ...</td>\n",
              "      <td>Explain the implied meaning underlying the off...</td>\n",
              "      <td>Describe how the target group might feel emoti...</td>\n",
              "      <td>Describe how the target group might react cogn...</td>\n",
              "      <td>Analyze the different aspects such as offensiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Juice Jews are worse that nukes. Caption to a ...</td>\n",
              "      <td>Informative</td>\n",
              "      <td>Anti-semitism is a serious problem that we nee...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Human</td>\n",
              "      <td>Jews are worse than nukes.</td>\n",
              "      <td>...</td>\n",
              "      <td>jews</td>\n",
              "      <td>religion</td>\n",
              "      <td>Analyze the offensiveness of the statement: Ju...</td>\n",
              "      <td>Identify the group of people that the speaker ...</td>\n",
              "      <td>Analyze the speaker's intention behind writing...</td>\n",
              "      <td>Explain the underlying power dynamics between ...</td>\n",
              "      <td>Explain the implied meaning underlying the off...</td>\n",
              "      <td>Describe how the target group might feel emoti...</td>\n",
              "      <td>Describe how the target group might react cogn...</td>\n",
              "      <td>Analyze the different aspects such as offensiv...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e571890-70a1-4b2c-a52e-809c4904074d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e571890-70a1-4b2c-a52e-809c4904074d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e571890-70a1-4b2c-a52e-809c4904074d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9a479ab3-cfeb-4a5c-95a7-1ad01943d722\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a479ab3-cfeb-4a5c-95a7-1ad01943d722')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9a479ab3-cfeb-4a5c-95a7-1ad01943d722 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "training_data"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "training_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofLk7bt7_6dW",
        "outputId": "9d435fff-40f4-4f77-d890-b4ecb7e6cdff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['hatespeech', 'csType', 'counterspeech', 'Suggest', 'Relevance',\n",
            "       'Aggressive', 'Complexity', 'Comments', 'source', 'claim',\n",
            "       'centralTopic', 'speakerIntent', 'targetGroup', 'relevantPowerDynamics',\n",
            "       'hatespeechImplication', 'targetGroupEmotionalReaction',\n",
            "       'targetGroupCognitiveReaction', 'hatespeechOffensiveness', 'id',\n",
            "       'is_high_quality', 'hs_id', 'hatespeechTarget', 'powerDynamics',\n",
            "       'prompt_offensiveness', 'prompt_target_group', 'prompt_speaker_intent',\n",
            "       'prompt_power_dynamics', 'prompt_implication',\n",
            "       'prompt_emotional_reaction', 'prompt_cognitive_reaction',\n",
            "       'prompt_cs_generation'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "columns = training_data.columns\n",
        "print(columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "smSz_WAB_6dX"
      },
      "outputs": [],
      "source": [
        "class DialoGPTDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/hateBERT\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        # Tokenize hate speech\n",
        "        hate_inputs = self.tokenizer(\n",
        "            row[\"hatespeech\"],\n",
        "            return_tensors='pt',\n",
        "            max_length=128,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "        # Tokenize counterspeech\n",
        "        counter_inputs = self.tokenizer(\n",
        "            row[\"counterspeech\"],\n",
        "            return_tensors='pt',\n",
        "            max_length=128,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "\n",
        "        # Define intent categories\n",
        "        categories = {\n",
        "            'informative': 0,\n",
        "            'questioning': 1,\n",
        "            'denouncing': 2,\n",
        "            'positive': 3,\n",
        "            'humor': 4\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            'input_ids': hate_inputs['input_ids'].squeeze(0),\n",
        "            'attention_mask': hate_inputs['attention_mask'].squeeze(0),\n",
        "            'counter_speech': counter_inputs['input_ids'].squeeze(0),\n",
        "            'intent_id': torch.tensor(categories[row[\"csType\"].lower()], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjDAavD0_6dX",
        "outputId": "4fa0dee1-8852-4c22-dc9d-69e7432beafc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9532\n",
            "2971\n",
            "1470\n",
            "{'input_ids': tensor([  101,  2672,  1996,  4895,  2071,  2831,  2000,  2216,  4004,  1998,\n",
            "         3060,  3741,  3625,  2005,  3938,  1009,  1997,  1996, 10796,  1999,\n",
            "         1996, 17401,  2612,  1997, 22604,  2006,  2023, 14636,  2055,  4785,\n",
            "         2689,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'counter_speech': tensor([  101,  1996,  2149,  2003,  1996,  2117,  2087,  8554, 20807,  2406,\n",
            "         1999,  1996,  2088,  1011,  2004,  1996,  2088,  1521,  1055,  5221,\n",
            "         3919,  1998,  3293,  2373,  1012,  2057,  2024,  2035,  2000,  7499,\n",
            "         2182,  1998,  2342,  2000,  2147,  2192,  1999,  2192,  2000,  3443,\n",
            "         9084,  2689,  1010,  2004,  4941,  2000,  7302,  1996,  4344,  2000,\n",
            "         2500,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'intent_id': tensor(0)}\n"
          ]
        }
      ],
      "source": [
        "train_dataset = DialoGPTDataset(training_data)\n",
        "test_dataset = DialoGPTDataset(testing_data)\n",
        "validation_dataset = DialoGPTDataset(validation_data)\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))\n",
        "print(len(validation_dataset))\n",
        "\n",
        "print(train_dataset[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureEncoder(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, next_input):\n",
        "        super(FeatureEncoder, self).__init__()\n",
        "        self.model = AutoModel.from_pretrained('GroNLP/hateBERT')\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_size = next_input\n",
        "\n",
        "        self.informative_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.questioning_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.denouncing_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.positive_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.humor_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hate_speech_h = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        informative_e = self.informative_head(hate_speech_h)\n",
        "        questioning_e = self.questioning_head(hate_speech_h)\n",
        "        denouncing_e = self.denouncing_head(hate_speech_h)\n",
        "        positive_e = self.positive_head(hate_speech_h)\n",
        "        humor_e = self.humor_head(hate_speech_h)\n",
        "\n",
        "        return informative_e, questioning_e, denouncing_e, positive_e, humor_e, hate_speech_h"
      ],
      "metadata": {
        "id": "LpupYCINMIin"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_encoder = FeatureEncoder(input_dim=128, hidden_dim=768, next_input=100)\n",
        "print(feature_encoder(train_dataset[0]['input_ids'].unsqueeze(0), train_dataset[0]['attention_mask'].unsqueeze(0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyXBzACbO4b6",
        "outputId": "5652bd54-a540-4980-bde6-8b0ddd5e8599"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[0.1507, 0.0000, 0.4983, 0.0000, 0.2802, 0.0000, 0.4504, 0.0000, 0.0000,\n",
            "         0.2126, 0.4089, 0.0000, 0.0000, 0.2820, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.6674, 0.0000, 0.0000, 0.0000, 0.5073, 0.0842,\n",
            "         0.4929, 0.0430, 0.0000, 0.0000, 0.3931, 0.4724, 0.0000, 0.4887, 0.1607,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0886, 0.0000, 0.4153, 0.0000,\n",
            "         0.0000, 0.2787, 0.0000, 0.3752, 0.0000, 0.1992, 0.0091, 0.0000, 0.0813,\n",
            "         0.4118, 0.1761, 0.4594, 0.5128, 0.0692, 0.0000, 0.2102, 0.1904, 0.0000,\n",
            "         0.4165, 0.0000, 0.0802, 0.4723, 0.0053, 0.0000, 0.3038, 0.0792, 0.1290,\n",
            "         0.1257, 0.5859, 0.1101, 0.3352, 0.0000, 0.0000, 0.0000, 0.0129, 0.0000,\n",
            "         0.0000, 0.1656, 0.0000, 0.0000, 0.1509, 0.0000, 0.0000, 0.0000, 0.1468,\n",
            "         0.3365, 0.6771, 0.0000, 0.0800, 0.3117, 0.0129, 0.0000, 0.2357, 0.6165,\n",
            "         0.2661]], grad_fn=<ReluBackward0>), tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.7632, 0.0000, 0.0000, 0.0000, 0.1278,\n",
            "         0.0000, 0.5652, 0.0000, 0.5518, 0.2304, 0.0373, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.8341, 0.1004, 0.0000, 0.0970, 0.0000, 0.4034,\n",
            "         0.0648, 0.1946, 0.0000, 0.0000, 0.3651, 0.0641, 0.4853, 0.0720, 0.0000,\n",
            "         0.4584, 0.3145, 0.0000, 0.1777, 0.0801, 0.0000, 0.2031, 0.1683, 0.0000,\n",
            "         0.2515, 0.0000, 0.0000, 0.1787, 0.0000, 0.0000, 0.1393, 0.0000, 0.0337,\n",
            "         0.0000, 0.0000, 0.0000, 0.2673, 0.0000, 0.0000, 0.0000, 0.0000, 0.4025,\n",
            "         0.0000, 0.0000, 0.0000, 0.1313, 0.0000, 0.3295, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0836, 0.0000, 0.0000, 0.0062, 0.0781, 0.2703, 0.3498,\n",
            "         0.0000, 0.0000, 0.8157, 0.0000, 0.0675, 0.0000, 0.0000, 0.0000, 0.0695,\n",
            "         0.0000, 0.0102, 0.1493, 0.2643, 0.3043, 0.5212, 0.3109, 0.1043, 0.0000,\n",
            "         0.0000]], grad_fn=<ReluBackward0>), tensor([[0.3418, 0.0787, 0.5491, 0.2158, 0.0000, 0.0000, 0.0632, 0.1212, 0.0000,\n",
            "         0.2823, 0.1162, 0.6543, 0.0674, 0.0000, 0.1230, 0.0000, 0.0000, 0.3485,\n",
            "         0.3036, 0.0000, 0.0000, 0.0000, 0.0000, 0.2199, 0.0000, 0.0994, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0282, 0.0000, 0.8797,\n",
            "         0.0190, 0.2890, 0.2490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5289,\n",
            "         0.1581, 0.3042, 0.0000, 0.0000, 0.4356, 0.0000, 0.2300, 0.0000, 0.0000,\n",
            "         0.0521, 0.2671, 0.0000, 0.0000, 0.0692, 0.6865, 0.0000, 0.0797, 0.2214,\n",
            "         0.3087, 0.0000, 0.3244, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0587,\n",
            "         0.0000, 0.2980, 0.2706, 0.3955, 0.0000, 0.0000, 0.3054, 0.2613, 0.0460,\n",
            "         0.2506, 0.0000, 0.3868, 0.0263, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.1136, 0.0000, 0.5188, 0.2913, 0.0000, 0.0000, 0.2290, 0.0000,\n",
            "         0.0000]], grad_fn=<ReluBackward0>), tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.4154, 0.0000, 0.0196, 0.0000, 0.5219,\n",
            "         0.4251, 0.0000, 0.3247, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.3006, 0.0000, 0.0389, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0529, 0.1744, 0.0000, 0.0000, 0.1546, 0.0000,\n",
            "         0.0000, 0.2196, 0.3562, 0.3436, 0.0000, 0.3438, 0.0282, 0.0000, 0.3894,\n",
            "         0.0000, 0.1067, 0.0000, 0.1827, 0.0000, 0.0000, 0.0000, 0.0796, 0.0861,\n",
            "         0.4647, 0.1908, 0.1187, 0.0000, 0.0000, 0.0000, 0.0000, 0.5433, 0.0000,\n",
            "         0.0000, 0.0000, 0.4574, 0.0000, 0.1424, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0488, 0.0000, 0.3007, 0.0000, 0.1127, 0.0000, 0.1533, 0.3581,\n",
            "         0.2293, 0.1125, 0.0000, 0.0000, 0.0000, 0.0064, 0.0000, 0.0077, 0.0000,\n",
            "         0.2719, 0.0000, 0.0000, 0.0000, 0.5099, 0.0951, 0.0000, 0.0000, 0.2745,\n",
            "         0.1539]], grad_fn=<ReluBackward0>), tensor([[0.0000, 0.0000, 0.0000, 0.2638, 0.0120, 0.2334, 0.0000, 0.2644, 0.0000,\n",
            "         0.0000, 0.1235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8421,\n",
            "         0.6374, 0.1170, 0.5219, 0.0000, 0.0000, 0.2224, 0.0000, 0.0647, 0.0218,\n",
            "         0.0000, 0.0000, 0.1366, 0.0000, 0.1142, 0.0000, 0.0000, 0.3173, 0.0000,\n",
            "         0.0000, 0.7002, 0.0000, 0.0000, 0.0367, 0.0857, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.1572, 0.0000, 0.0000, 0.0436, 0.0000, 0.0000, 0.0132,\n",
            "         0.0000, 0.0000, 0.1886, 0.0000, 0.2551, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.2597, 0.0000, 0.0000, 0.0600, 0.0000, 0.1413, 0.1735, 0.0000, 0.1480,\n",
            "         0.0000, 0.3869, 0.0000, 0.3978, 0.3520, 0.0000, 0.2921, 0.1580, 0.5071,\n",
            "         0.1956, 0.0000, 0.1934, 0.0756, 0.7720, 0.0000, 0.2519, 0.3683, 0.4652,\n",
            "         0.0572, 0.0000, 0.1379, 0.1794, 0.4494, 0.0000, 0.4212, 0.0000, 0.2417,\n",
            "         0.1323]], grad_fn=<ReluBackward0>), tensor([[-1.2316e-01,  2.5760e-01, -6.8412e-01,  4.6821e-01,  8.0943e-01,\n",
            "         -2.5792e-01,  1.5351e-01,  1.3639e+00, -1.0266e+00,  1.3265e-01,\n",
            "         -6.1926e-01,  2.1133e-01, -4.9460e-01,  7.6190e-01, -6.9545e-02,\n",
            "          6.8312e-01,  3.7021e-01, -4.6095e-01,  3.3195e-01,  5.0576e-01,\n",
            "          2.4192e-01, -2.2491e-01,  3.1872e-01,  8.5852e-01,  1.3688e-01,\n",
            "         -4.0543e-01,  5.2988e-01,  7.3655e-01, -1.8011e-01,  4.7114e-01,\n",
            "          1.1463e-01, -1.9435e-01,  3.9097e-02, -1.4291e-01, -1.6129e-01,\n",
            "         -4.2231e-01, -7.1753e-01,  2.2965e-01, -1.0829e-01,  4.8140e-01,\n",
            "         -2.8108e-01,  3.4256e-02, -2.7372e-01, -4.2401e-01,  1.7613e-01,\n",
            "          5.1272e-01, -1.1607e+00,  9.1711e-01,  4.1866e-01,  1.1515e-01,\n",
            "          2.4045e-02,  4.7473e-01,  5.9433e-01, -1.7153e-01,  1.6978e-01,\n",
            "          6.4695e-01, -4.9544e-01,  4.1428e-02, -1.0952e+00,  3.7567e-03,\n",
            "          2.9936e-01, -5.2084e-01, -4.3595e-02,  3.3521e-01,  1.2925e-01,\n",
            "          2.1945e-01,  1.5714e-01, -5.9910e-01, -3.5057e-02,  4.0079e-01,\n",
            "         -9.8172e-02,  3.8298e-01, -7.9815e-01, -6.8081e-02, -5.0185e-01,\n",
            "         -1.1499e+00,  4.8555e-01,  5.9444e-01, -1.9008e-01,  2.0195e-01,\n",
            "         -2.1091e-01, -7.6863e-02, -9.0526e-01,  4.3959e-01, -4.6773e-01,\n",
            "         -1.8348e-01,  6.2463e-02,  1.1052e+00, -3.8372e-01,  1.5440e-01,\n",
            "         -2.4588e-01,  3.0191e-01,  3.5213e-01, -1.3883e-01,  1.1457e+00,\n",
            "         -4.6540e-01,  3.4221e-01,  2.6335e-01,  5.6252e-01,  4.1568e-01,\n",
            "         -7.6780e-01, -1.1107e+00,  4.1170e-01,  4.5548e-01, -5.5886e-01,\n",
            "         -6.0578e-01, -6.8058e-01, -3.3178e-01, -2.8615e-01, -1.0600e+00,\n",
            "          1.1757e+00, -1.6308e-01,  3.4663e-01, -6.9612e-01,  1.6039e-01,\n",
            "          6.7695e-01,  6.8573e-01, -4.1015e-01, -1.3529e-01,  3.5348e-01,\n",
            "          3.2437e-01,  2.6495e-01, -3.6578e-03, -7.7232e-02, -4.1760e-01,\n",
            "          1.2196e-01,  4.7131e-01, -1.5215e-01, -3.7126e-01, -1.7946e-01,\n",
            "          4.6674e-01,  7.4275e-01,  4.2055e-01, -3.5353e-01,  4.1961e-01,\n",
            "         -1.3581e-01,  1.5983e-01, -4.0132e-01,  1.1101e+00, -1.9269e-01,\n",
            "          6.2207e-01, -2.3745e-01, -1.8398e+00,  2.3780e-01,  9.0787e-02,\n",
            "          6.5546e-01, -3.2986e-01, -1.7356e-01, -1.8928e-01,  7.1867e-01,\n",
            "         -1.2658e-01,  6.1733e-02,  1.8678e-01, -3.1778e-01, -5.4623e-01,\n",
            "         -2.5240e-01, -4.4977e-01, -3.9046e-02,  7.4262e-01, -5.8837e-02,\n",
            "          1.6054e-01, -5.0865e-01,  1.7492e-01, -2.7634e-01,  1.2887e-01,\n",
            "          8.1764e-02,  5.0241e-02,  9.8645e-01, -4.3364e-01,  1.4911e-01,\n",
            "         -5.8697e-01, -6.5167e-01,  9.5687e-01, -1.8770e-01,  4.1894e-01,\n",
            "         -3.7152e-01,  6.5440e-01,  4.5212e-01, -8.6196e-02, -2.2374e-01,\n",
            "         -8.7534e-01,  2.2465e-01, -2.1325e-01,  6.3038e-01,  1.1065e-01,\n",
            "         -5.4311e-01, -5.1110e-02,  5.6019e-01,  1.1177e+00, -3.2925e-01,\n",
            "         -5.6906e-01,  1.7327e-01,  6.8197e-02,  3.8716e-01, -5.0439e-02,\n",
            "         -2.0217e-01,  1.4270e-01,  7.4871e-01,  2.7728e-01,  1.7624e-01,\n",
            "         -9.2496e-01,  2.3841e-01,  6.4823e-01, -4.1757e-01, -6.7736e-01,\n",
            "          2.4559e+00, -1.8675e-01,  1.0047e-01,  1.5118e-01,  5.0533e-01,\n",
            "         -4.2134e-01, -8.7587e-04, -4.5003e-02,  1.6084e-01, -6.0728e-01,\n",
            "          1.9793e-01, -7.8367e-01,  2.2306e-01, -2.2293e-01,  2.4963e-01,\n",
            "          6.9048e-01,  6.4160e-01, -1.2937e-01,  7.0448e-02, -5.7322e-02,\n",
            "          4.0691e-01,  5.9287e-01, -5.5968e-02,  8.0828e-01, -2.3386e-01,\n",
            "         -5.2182e-01, -3.5160e-01,  3.1023e-02, -1.1959e-01,  2.9238e-02,\n",
            "          1.0504e-01, -1.4949e-01,  1.1976e-01,  8.0820e-01,  8.3419e-02,\n",
            "         -3.6124e-01, -2.9663e-01, -6.0953e-01,  5.0977e-01,  4.5629e-01,\n",
            "          4.5553e-01,  5.1052e-01,  2.2577e-01, -3.3124e-01,  4.3715e-01,\n",
            "         -3.4963e-01,  3.9342e-01, -1.8828e-03, -3.4032e-01,  1.5296e-01,\n",
            "          8.7104e-02, -1.6105e-01,  5.3819e-01,  2.1507e-01, -6.3888e-01,\n",
            "         -7.4827e-02,  5.1822e-03, -1.8684e-01,  5.4644e-02, -2.3305e-01,\n",
            "         -7.6733e-01,  7.9099e-01,  9.4913e-02,  6.2855e-01,  1.3569e-01,\n",
            "          3.5545e-01,  6.2363e-01,  4.5772e-02, -1.6890e+00, -2.3884e-02,\n",
            "         -5.0119e-01,  1.3611e-01,  4.0873e-01, -1.5019e-01,  5.2313e-01,\n",
            "          6.4430e-01,  1.1717e+00, -9.5832e-01, -6.1409e-01, -8.0561e-01,\n",
            "         -1.6220e-01,  2.4920e-01, -8.2227e-01, -4.3588e-02, -2.6612e-02,\n",
            "          3.4783e-01, -7.0667e-01, -2.0241e-01, -9.8403e-01, -2.2646e-02,\n",
            "          2.2685e-01,  1.3894e-01, -6.7778e-01,  6.9484e-01, -5.4874e-02,\n",
            "         -6.6487e-02, -5.5729e-01,  3.6754e-02,  2.2070e-02, -7.1231e-01,\n",
            "          2.7916e-01, -4.7231e-04, -8.7007e-01, -3.1925e+00, -3.8667e-01,\n",
            "          1.9817e-01,  6.7628e-01, -1.0927e-01,  1.7100e-01,  2.4088e-01,\n",
            "          7.8297e-02, -4.5646e-01,  1.0410e-01,  3.8411e-01,  5.1960e-01,\n",
            "          9.7735e-02, -5.6284e-01,  4.5912e-01,  2.0076e-01,  3.5869e-01,\n",
            "         -2.8793e-03,  3.4292e-01,  4.7845e-01, -5.0375e-02, -1.2040e-01,\n",
            "         -2.4911e-01,  2.2337e-01,  4.4491e-01,  2.2470e-01,  2.1969e-01,\n",
            "         -7.0901e-01, -7.5797e-02, -4.0109e-01,  2.1902e-01, -3.0490e-01,\n",
            "         -1.5279e-01, -1.9591e-01,  3.9023e-01,  3.0864e-01, -9.3815e-02,\n",
            "          5.2040e-01, -2.5760e-01,  3.0921e-01, -2.5657e-01, -6.5282e-01,\n",
            "         -4.6588e-02, -3.0058e-01,  9.0686e-01, -1.7764e-01, -1.2411e-01,\n",
            "         -8.6077e-01,  2.9516e-01,  4.3452e-01,  2.8654e-01,  5.3828e-01,\n",
            "          8.1635e-01, -3.2586e-01, -2.4166e-01, -2.7436e-01,  7.0768e-01,\n",
            "          1.5937e-01, -2.4538e-01,  1.2337e-01,  1.3415e-01,  4.9002e-01,\n",
            "          3.2754e-01,  2.2374e-02, -1.3236e-01, -5.5545e-02, -2.2924e-01,\n",
            "         -5.6747e-01,  1.2857e-01, -2.7168e-01, -9.6040e-01,  3.1013e-01,\n",
            "         -5.3072e-01, -1.0119e+00, -2.3787e-01, -1.0075e+00, -4.9160e-01,\n",
            "         -3.0076e-01, -1.0902e-01,  2.2922e-02, -6.6215e-01, -2.1729e-01,\n",
            "         -1.3537e-01,  8.3462e-01,  5.5448e-01, -1.3850e-01, -4.5189e-01,\n",
            "         -3.4199e-01,  5.7501e-02, -3.8553e-02,  4.5402e-01, -9.7354e-01,\n",
            "         -2.1974e-01,  5.9555e-02,  8.3421e-01, -6.1270e-02,  2.3983e-01,\n",
            "         -6.1180e-01,  2.1610e-01, -5.2339e-01, -4.2720e-01, -6.3771e-01,\n",
            "         -6.5095e-01, -7.1220e-01,  3.3096e-01, -2.3564e-01, -1.2212e-01,\n",
            "          9.8597e-01, -2.9605e-02,  1.9035e-01,  4.4752e-01, -7.2772e-01,\n",
            "          1.5666e-01, -2.6520e-01,  7.5874e-01,  2.2994e-01, -8.1482e-02,\n",
            "          4.4986e-01,  2.9370e-02,  3.9530e-01,  1.3770e-01,  9.5294e-01,\n",
            "         -5.7926e-02, -2.3266e-01, -3.7861e-02, -4.3921e-01, -2.4357e-01,\n",
            "         -4.3165e-01, -7.9695e-02, -6.7831e-01, -2.0219e-01,  4.1504e-02,\n",
            "          1.5968e-01, -4.6000e-02,  6.7886e-01, -3.3935e-01, -1.3622e-01,\n",
            "         -7.7347e-01, -2.9268e-02,  4.9231e-01, -6.4105e-01,  8.3317e-02,\n",
            "          4.7684e-01, -4.7184e-01, -3.9823e-01,  6.0697e-01, -5.7826e-01,\n",
            "          2.1868e-01,  3.8097e-01, -2.8609e-03, -4.8541e-01, -1.0757e+00,\n",
            "         -7.1333e-01,  4.5390e-01, -2.0179e-01,  4.3082e-01,  9.3196e-01,\n",
            "          2.4342e-01, -8.4648e-02, -1.6379e-01, -2.6147e-01,  1.8407e-01,\n",
            "         -8.2096e-01,  6.0947e-02,  5.6156e-01,  8.4814e-01, -5.1333e-01,\n",
            "         -4.9439e-01,  2.7934e-01,  4.8919e-02,  1.4163e-01, -2.6337e-01,\n",
            "         -3.5863e-01, -2.6333e-01, -4.0775e-01, -1.9226e-01, -1.3125e-01,\n",
            "         -4.9540e-02, -2.3981e-01,  8.2045e-01, -3.0231e-03, -4.5013e-01,\n",
            "         -1.8484e-01,  2.3027e-01,  3.3701e-01, -1.0127e-01, -3.4452e-01,\n",
            "         -1.9135e-01, -2.0341e-01,  3.9551e-01,  3.9827e-01,  5.0469e-01,\n",
            "         -1.2788e-01,  6.4177e-01, -6.9860e-01, -2.0280e-01,  1.3127e-01,\n",
            "          2.2284e-01, -3.1996e-01,  2.2150e-01,  1.7712e-01,  2.1998e-01,\n",
            "         -7.3683e-01,  5.1713e-01,  3.6159e-02, -3.6509e-01, -4.3329e-01,\n",
            "         -1.2380e-01,  1.8382e-01,  4.6504e-01, -9.2250e-01, -2.0718e-01,\n",
            "         -2.3360e-01,  2.2939e-01,  6.6333e-01, -6.3954e-01,  5.7905e-02,\n",
            "         -3.3021e-01,  2.4985e-02, -2.6652e-01, -1.8399e-01,  4.3828e-01,\n",
            "          4.8261e-01, -4.4609e-01,  8.0297e-01,  1.0476e-01, -1.1147e+00,\n",
            "         -3.8298e-06, -3.2108e-01, -2.2974e-01, -5.5197e-01, -9.1232e-01,\n",
            "          1.5148e-01,  6.9941e-01, -5.7468e-02, -2.8318e-01, -3.0531e-01,\n",
            "          7.6688e-02, -2.6689e-01, -4.4704e-01,  4.7444e-01,  4.6342e-02,\n",
            "         -3.6947e-01, -7.6067e-01, -7.5091e-01,  5.0563e-01, -6.5453e-01,\n",
            "          4.0746e-01,  2.8565e-01, -2.2232e-01, -6.4757e-01, -5.3656e-01,\n",
            "         -1.3977e-03, -1.0704e+00,  5.3240e-01, -2.9782e-01, -5.0650e-01,\n",
            "         -4.1498e-02, -4.4396e-01,  2.0083e-02,  1.7154e-01, -3.1965e-02,\n",
            "         -6.9168e-01, -4.4352e-01,  8.8167e-01, -2.6560e-01, -5.4387e-01,\n",
            "         -3.6767e-01,  3.1593e-01, -1.7683e-01,  2.3699e-01, -9.4360e-02,\n",
            "         -1.5392e-01, -4.3483e-02,  4.9739e-01,  8.1367e-02, -6.3716e-03,\n",
            "         -2.6060e-01,  1.0677e+00, -1.2285e+00,  1.0485e+00,  1.0843e+00,\n",
            "         -2.1918e-01, -1.6651e-01, -8.3574e-03, -1.3463e-01, -1.6047e-01,\n",
            "          9.8834e-02,  6.2214e-01, -2.0275e-01,  2.0175e-01, -3.1997e-01,\n",
            "         -4.9679e-01,  3.3211e-01,  3.8114e-01,  5.7119e-01,  5.1291e-01,\n",
            "          1.8488e-02, -4.2402e-01,  1.7790e-01, -1.1871e+00, -2.0845e-01,\n",
            "         -3.9290e-02,  5.5680e-01,  8.9255e-01, -5.8632e-02,  3.3880e-01,\n",
            "          9.5283e-02,  9.5194e-03, -2.3480e-02, -1.6059e-01,  3.4324e-01,\n",
            "          3.7971e-02,  2.7206e-01,  1.3271e-01,  3.6109e-01,  2.9792e-01,\n",
            "          5.6152e-01,  7.6749e-01, -4.0285e-02, -1.6407e-01, -6.9849e-01,\n",
            "         -5.7901e-01,  7.9291e-01,  9.6179e-02,  8.0835e-03, -6.0179e-01,\n",
            "         -2.1675e-01,  1.0679e-01,  9.2902e-01,  3.8888e-01,  1.2707e+00,\n",
            "          2.8934e-01, -7.8272e-01, -5.9534e-01,  1.0079e+00,  1.8520e-01,\n",
            "         -5.8274e-01, -7.6067e-01,  9.1246e-01,  7.4106e-01,  3.6579e-01,\n",
            "          2.6696e-01,  3.0449e-01,  4.0488e-01, -4.7378e-02, -4.9712e-01,\n",
            "          3.2128e-01,  7.3942e-02, -2.2706e-01, -4.1623e-02, -4.0169e-01,\n",
            "         -6.9344e-02, -6.2745e-02,  4.8091e-01,  2.4996e-01,  2.6361e-01,\n",
            "          1.2227e-01,  8.5500e-01, -1.2661e+00, -1.7783e-01, -5.6633e-02,\n",
            "          8.3859e-01,  1.1827e-01,  4.8322e-01,  4.5807e-01, -1.1280e-02,\n",
            "         -5.8511e-02,  3.8427e-01, -5.6434e-03,  1.6789e-01,  1.0114e-01,\n",
            "          1.1220e-01, -5.1211e-01,  8.3886e-01, -2.4258e-01, -8.4999e-01,\n",
            "         -4.9027e-01,  3.7390e-01,  4.1485e-01, -3.3120e-01,  9.7744e-01,\n",
            "         -4.5607e-01, -7.3514e-03, -7.3092e-02,  8.7236e-02, -3.0596e-01,\n",
            "          4.6145e-01,  1.8278e-01,  1.9414e-01,  5.5773e-01, -6.4275e-01,\n",
            "         -4.8545e-01,  5.0916e-01, -5.0577e-01, -9.8773e-01,  3.9029e-01,\n",
            "         -7.1127e-02,  1.7022e-01, -6.7253e-01,  7.6379e-01,  1.0064e-01,\n",
            "         -1.7974e-01,  2.8179e-01, -2.8583e-02, -5.7483e-01, -2.1858e-01,\n",
            "          3.5220e-01,  2.2009e-02,  1.3801e-01,  1.1380e+00,  3.3350e-02,\n",
            "         -1.3364e-01,  3.1937e-01, -6.0456e-01,  4.3840e-01,  1.6217e-02,\n",
            "          2.9566e-01,  4.8918e-01, -3.1255e-01,  3.8324e-01, -7.4790e-01,\n",
            "         -6.5821e-01,  5.5319e-01,  1.8778e-01, -4.6856e-01, -8.2878e-02,\n",
            "         -1.4972e-02, -5.5359e-01,  7.8357e-01, -6.4829e-01,  2.1437e-03,\n",
            "          2.2975e-01,  3.1752e-02, -5.4749e-01, -1.0020e+00, -8.0303e-02,\n",
            "          3.9623e-02, -5.9870e-02, -3.5461e-01, -3.1485e-02,  1.2653e-01,\n",
            "         -2.3913e-01,  3.7739e-01, -3.7753e+00, -9.8182e-01, -2.3795e-01,\n",
            "         -8.2952e-01, -5.5751e-01,  2.5009e-01,  7.1639e-01, -4.8086e-01,\n",
            "         -1.4179e-02, -1.4914e-01, -1.1136e-01, -2.0262e-01,  1.9010e-02,\n",
            "         -7.5536e-01,  5.8692e-01,  2.5884e-01]], grad_fn=<SliceBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CounterSpeechNetwork(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, encoder_output):\n",
        "        super(CounterSpeechNetwork, self).__init__()\n",
        "\n",
        "        self.feature_encoder = FeatureEncoder(input_dim, hidden_dim, encoder_output)\n",
        "\n",
        "        self.informative_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "        self.questioning_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "        self.denouncing_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "        self.positive_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "        self.humor_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "\n",
        "        self.informative_fusion = torch.nn.Linear(hidden_dim + encoder_output, self.informative_decoder.config.d_model)\n",
        "        self.questioning_fusion = torch.nn.Linear(hidden_dim + encoder_output, self.questioning_decoder.config.d_model)\n",
        "        self.denouncing_fusion = torch.nn.Linear(hidden_dim + encoder_output, self.denouncing_decoder.config.d_model)\n",
        "        self.positive_fusion = torch.nn.Linear(hidden_dim + encoder_output, self.positive_decoder.config.d_model)\n",
        "        self.humor_fusion = torch.nn.Linear(hidden_dim + encoder_output, self.humor_decoder.config.d_model)\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, intent_id, counter_speech=None):\n",
        "        informative_e, questioning_e, denouncing_e, positive_e, humor_e, hate_speech_h = self.feature_encoder(input_ids, attention_mask)\n",
        "\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        fused = torch.zeros(batch_size, 1, self.informative_decoder.config.d_model, device=input_ids.device)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            if intent_id[i] == 0:\n",
        "                fused[i] = self.informative_fusion(torch.cat((hate_speech_h[i], informative_e[i]), dim=-1)).unsqueeze(0)\n",
        "            elif intent_id[i] == 1:\n",
        "                fused[i] = self.questioning_fusion(torch.cat((hate_speech_h[i], questioning_e[i]), dim=-1)).unsqueeze(0)\n",
        "            elif intent_id[i] == 2:\n",
        "                fused[i] = self.denouncing_fusion(torch.cat((hate_speech_h[i], denouncing_e[i]), dim=-1)).unsqueeze(0)\n",
        "            elif intent_id[i] == 3:\n",
        "                fused[i] = self.positive_fusion(torch.cat((hate_speech_h[i], positive_e[i]), dim=-1)).unsqueeze(0)\n",
        "            elif intent_id[i] == 4:\n",
        "                fused[i] = self.humor_fusion(torch.cat((hate_speech_h[i], humor_e[i]), dim=-1)).unsqueeze(0)\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid intent_id: {intent_id[i]}\")\n",
        "\n",
        "        if counter_speech is not None:\n",
        "            losses = []\n",
        "            for i in range(batch_size):\n",
        "                if intent_id[i] == 0:\n",
        "                    output = self.informative_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
        "                elif intent_id[i] == 1:\n",
        "                    output = self.questioning_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
        "                elif intent_id[i] == 2:\n",
        "                    output = self.denouncing_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
        "                elif intent_id[i] == 3:\n",
        "                    output = self.positive_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
        "                elif intent_id[i] == 4:\n",
        "                    output = self.humor_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
        "                losses.append(output.loss)\n",
        "            avg_loss = sum(losses) / len(losses)  # Average loss across the batch\n",
        "            return None, avg_loss  # No decoded text during training\n",
        "        else:\n",
        "            decoded_texts = []\n",
        "            for i in range(batch_size):\n",
        "                if intent_id[i] == 0:\n",
        "                    output = self.informative_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
        "                elif intent_id[i] == 1:\n",
        "                    output = self.questioning_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
        "                elif intent_id[i] == 2:\n",
        "                    output = self.denouncing_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
        "                elif intent_id[i] == 3:\n",
        "                    output = self.positive_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
        "                elif intent_id[i] == 4:\n",
        "                    output = self.humor_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
        "                decoded_texts.append(self.tokenizer.decode(output[0], skip_special_tokens=True))\n",
        "            return decoded_texts, None  # Decoded text during inference, no loss"
      ],
      "metadata": {
        "id": "8qxFuKQrRtuO"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "counterspeechnetwork = CounterSpeechNetwork(input_dim=128, hidden_dim=768, encoder_output=256)\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    intent_id = batch['intent_id']\n",
        "    counter_speech = batch['counter_speech']\n",
        "\n",
        "    print(counterspeechnetwork(input_ids, attention_mask, intent_id, counter_speech))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dVxqr6WWc8j",
        "outputId": "1bf35674-29e9-4ad9-b9a1-65898292fc9e"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, tensor(15.3043, grad_fn=<DivBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CounterSpeechNetwork(input_dim=128, hidden_dim=768, encoder_output=256)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "\n",
        "    # Wrap train_dataloader with tqdm for training progress\n",
        "    train_loop = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs} [Train]\", leave=False)\n",
        "    for batch in train_loop:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        counter_speech = batch['counter_speech'].to(device)\n",
        "        intent_ids = batch['intent_id'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Process the entire batch at once\n",
        "        _, loss = model(input_ids, attention_mask, intent_ids, counter_speech)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Update tqdm with current batch loss\n",
        "        train_loop.set_postfix({'batch_loss': loss.item(), 'avg_loss': total_train_loss / (train_loop.n + 1)})\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} | Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    total_val_loss = 0.0\n",
        "\n",
        "    # Wrap validation_dataloader with tqdm for validation progress\n",
        "    val_loop = tqdm(validation_dataloader, desc=f\"Epoch {epoch + 1}/{epochs} [Validation]\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loop:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            counter_speech = batch['counter_speech'].to(device)\n",
        "            intent_ids = batch['intent_id'].to(device)\n",
        "\n",
        "            # Process the entire batch at once\n",
        "            _, loss = model(input_ids, attention_mask, intent_ids, counter_speech)\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            # Update tqdm with current batch loss\n",
        "            val_loop.set_postfix({'batch_loss': loss.item(), 'avg_loss': total_val_loss / (val_loop.n + 1)})\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(validation_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} | Validation Loss: {avg_val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "du_G6NX9c_MN",
        "outputId": "01eb8d9f-36ee-4632-a7ff-bb39026481cd"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 26.12 MiB is free. Process 3367 has 14.71 GiB memory in use. Of the allocated memory 13.95 GiB is allocated by PyTorch, and 649.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-1a441a5a11bb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1341\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1327\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     )\n\u001b[0;32m-> 1329\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 26.12 MiB is free. Process 3367 has 14.71 GiB memory in use. Of the allocated memory 13.95 GiB is allocated by PyTorch, and 649.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test evaluation\n",
        "model.eval()\n",
        "test_predictions = []\n",
        "test_references = []\n",
        "\n",
        "# Wrap test_dataloader with tqdm for test progress\n",
        "test_loop = tqdm(test_dataloader, desc=\"Test Evaluation\", leave=True)\n",
        "with torch.no_grad():\n",
        "    for batch in test_loop:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        counter_speech = batch['counter_speech'].to(device)  # Reference texts\n",
        "        intent_ids = batch['intent_id'].to(device)\n",
        "\n",
        "        # Generate predictions without providing counter_speech\n",
        "        predictions, _ = model(input_ids, attention_mask, intent_ids)\n",
        "\n",
        "        # Decode reference texts\n",
        "        references = [model.tokenizer.decode(cs, skip_special_tokens=True) for cs in counter_speech]\n",
        "\n",
        "        test_predictions.extend(predictions)\n",
        "        test_references.extend(references)\n",
        "\n",
        "        # Update tqdm with progress stats (e.g., number of predictions)\n",
        "        test_loop.set_postfix({'predictions': len(test_predictions)})\n",
        "\n",
        "# Final output\n",
        "print(f\"Generated {len(test_predictions)} test predictions\")"
      ],
      "metadata": {
        "id": "2ChcK0JiiHeC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36aff3cc8ee845b08abd7f18589726fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5df75b26d1d464fb722dff990b5476a",
              "IPY_MODEL_00606f57d8884a8da09c02a2b181667c",
              "IPY_MODEL_5ae640fb971841d9b86737e6fd0b4c78"
            ],
            "layout": "IPY_MODEL_452dc6a25a544daab3217fae74b699e9"
          }
        },
        "f5df75b26d1d464fb722dff990b5476a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fccb872427ac46018921c52b405210ea",
            "placeholder": "​",
            "style": "IPY_MODEL_1274c2be26b64ab3b4ac358f7606a310",
            "value": "Downloading builder script: 100%"
          }
        },
        "00606f57d8884a8da09c02a2b181667c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa6a137ee63491cb9a5f54e44095154",
            "max": 7021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13cfef767914493fb7c16b42845c4c45",
            "value": 7021
          }
        },
        "5ae640fb971841d9b86737e6fd0b4c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95abeb3513704f59b66711a516c6130a",
            "placeholder": "​",
            "style": "IPY_MODEL_4d09db8336c340e4be9bc537537f4b0d",
            "value": " 7.02k/7.02k [00:00&lt;00:00, 436kB/s]"
          }
        },
        "452dc6a25a544daab3217fae74b699e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fccb872427ac46018921c52b405210ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1274c2be26b64ab3b4ac358f7606a310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baa6a137ee63491cb9a5f54e44095154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13cfef767914493fb7c16b42845c4c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95abeb3513704f59b66711a516c6130a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d09db8336c340e4be9bc537537f4b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}