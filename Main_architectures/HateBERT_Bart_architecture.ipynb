{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QJ-yxJ6P_6dU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, Trainer, TrainingArguments, BartForConditionalGeneration\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from torch.optim import Adam\n",
    "from accelerate import Accelerator\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239,
     "referenced_widgets": [
      "36aff3cc8ee845b08abd7f18589726fa",
      "f5df75b26d1d464fb722dff990b5476a",
      "00606f57d8884a8da09c02a2b181667c",
      "5ae640fb971841d9b86737e6fd0b4c78",
      "452dc6a25a544daab3217fae74b699e9",
      "fccb872427ac46018921c52b405210ea",
      "1274c2be26b64ab3b4ac358f7606a310",
      "baa6a137ee63491cb9a5f54e44095154",
      "13cfef767914493fb7c16b42845c4c45",
      "95abeb3513704f59b66711a516c6130a",
      "4d09db8336c340e4be9bc537537f4b0d"
     ]
    },
    "id": "vTDocM7nI_Hw",
    "outputId": "f3d7a035-b43f-46dc-d8e4-166f70fc7b90"
   },
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "\n",
    "# meteor = load(\"meteor\")\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eLC8QX4qI_Hw"
   },
   "outputs": [],
   "source": [
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hj0qY8zOI_Hx",
    "outputId": "087c651e-4068-420a-a242-4f2ba44c48ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/dhruv/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnoel22338\u001b[0m (\u001b[33mnlp_project_team\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login --relogin --verify f59d448beb3315f3efbc5a0a80d9d2c346926308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "B6MBEOJg_6dV"
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('../Dataset/train.csv')\n",
    "testing_data = pd.read_csv('../Dataset/test.csv')\n",
    "validation_data = pd.read_csv('../Dataset/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "id": "KPdXrxQg_6dW",
    "outputId": "da88817b-93ac-4215-bfa8-7c8849baf2dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          hatespeech       csType  \\\n",
      "0  Maybe the UN could talk to those asian and afr...  Informative   \n",
      "1  Maybe the UN could talk to those asian and afr...  Questioning   \n",
      "2  Maybe the UN could talk to those asian and afr...   Denouncing   \n",
      "3  Maybe the UN could talk to those asian and afr...     Positive   \n",
      "4  Juice Jews are worse that nukes. Caption to a ...  Informative   \n",
      "\n",
      "                                       counterspeech Suggest  Relevance  \\\n",
      "0  The us is the second most polluting country in...       3        4.0   \n",
      "1  Doesn't everyone on the planet have a responsi...                3.0   \n",
      "2  The world would be a better place if people we...       1        1.0   \n",
      "3  You're right, ocean pollution is one of the ma...       3        4.0   \n",
      "4  Anti-semitism is a serious problem that we nee...       2        3.0   \n",
      "\n",
      "   Aggressive  Complexity  Comments source  \\\n",
      "0         2.0         3.0       NaN  Human   \n",
      "1         2.0         2.0       NaN  Human   \n",
      "2         2.0         2.0       NaN  Human   \n",
      "3         2.0         2.0       NaN  Human   \n",
      "4         2.0         2.0       NaN  Human   \n",
      "\n",
      "                                               claim  ... hatespeechTarget  \\\n",
      "0  The UN should focus on Asian and African natio...  ...     asian_people   \n",
      "1  The UN should focus on Asian and African natio...  ...     asian_people   \n",
      "2  The UN should focus on Asian and African natio...  ...     asian_people   \n",
      "3  The UN should focus on Asian and African natio...  ...     asian_people   \n",
      "4                         Jews are worse than nukes.  ...             jews   \n",
      "\n",
      "  powerDynamics                               prompt_offensiveness  \\\n",
      "0        racial  Analyze the offensiveness of the statement: Ma...   \n",
      "1        racial  Analyze the offensiveness of the statement: Ma...   \n",
      "2        racial  Analyze the offensiveness of the statement: Ma...   \n",
      "3        racial  Analyze the offensiveness of the statement: Ma...   \n",
      "4      religion  Analyze the offensiveness of the statement: Ju...   \n",
      "\n",
      "                                 prompt_target_group  \\\n",
      "0  Identify the group of people that the speaker ...   \n",
      "1  Identify the group of people that the speaker ...   \n",
      "2  Identify the group of people that the speaker ...   \n",
      "3  Identify the group of people that the speaker ...   \n",
      "4  Identify the group of people that the speaker ...   \n",
      "\n",
      "                               prompt_speaker_intent  \\\n",
      "0  Analyze the speaker's intention behind writing...   \n",
      "1  Analyze the speaker's intention behind writing...   \n",
      "2  Analyze the speaker's intention behind writing...   \n",
      "3  Analyze the speaker's intention behind writing...   \n",
      "4  Analyze the speaker's intention behind writing...   \n",
      "\n",
      "                               prompt_power_dynamics  \\\n",
      "0  Explain the underlying power dynamics between ...   \n",
      "1  Explain the underlying power dynamics between ...   \n",
      "2  Explain the underlying power dynamics between ...   \n",
      "3  Explain the underlying power dynamics between ...   \n",
      "4  Explain the underlying power dynamics between ...   \n",
      "\n",
      "                                  prompt_implication  \\\n",
      "0  Explain the implied meaning underlying the off...   \n",
      "1  Explain the implied meaning underlying the off...   \n",
      "2  Explain the implied meaning underlying the off...   \n",
      "3  Explain the implied meaning underlying the off...   \n",
      "4  Explain the implied meaning underlying the off...   \n",
      "\n",
      "                           prompt_emotional_reaction  \\\n",
      "0  Describe how the target group might feel emoti...   \n",
      "1  Describe how the target group might feel emoti...   \n",
      "2  Describe how the target group might feel emoti...   \n",
      "3  Describe how the target group might feel emoti...   \n",
      "4  Describe how the target group might feel emoti...   \n",
      "\n",
      "                           prompt_cognitive_reaction  \\\n",
      "0  Describe how the target group might react cogn...   \n",
      "1  Describe how the target group might react cogn...   \n",
      "2  Describe how the target group might react cogn...   \n",
      "3  Describe how the target group might react cogn...   \n",
      "4  Describe how the target group might react cogn...   \n",
      "\n",
      "                                prompt_cs_generation  \n",
      "0  Analyze the different aspects such as offensiv...  \n",
      "1  Analyze the different aspects such as offensiv...  \n",
      "2  Analyze the different aspects such as offensiv...  \n",
      "3  Analyze the different aspects such as offensiv...  \n",
      "4  Analyze the different aspects such as offensiv...  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(training_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofLk7bt7_6dW",
    "outputId": "9d435fff-40f4-4f77-d890-b4ecb7e6cdff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hatespeech', 'csType', 'counterspeech', 'Suggest', 'Relevance',\n",
      "       'Aggressive', 'Complexity', 'Comments', 'source', 'claim',\n",
      "       'centralTopic', 'speakerIntent', 'targetGroup', 'relevantPowerDynamics',\n",
      "       'hatespeechImplication', 'targetGroupEmotionalReaction',\n",
      "       'targetGroupCognitiveReaction', 'hatespeechOffensiveness', 'id',\n",
      "       'is_high_quality', 'hs_id', 'hatespeechTarget', 'powerDynamics',\n",
      "       'prompt_offensiveness', 'prompt_target_group', 'prompt_speaker_intent',\n",
      "       'prompt_power_dynamics', 'prompt_implication',\n",
      "       'prompt_emotional_reaction', 'prompt_cognitive_reaction',\n",
      "       'prompt_cs_generation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns = training_data.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "smSz_WAB_6dX"
   },
   "outputs": [],
   "source": [
    "class DialoGPTDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/hateBERT\")\n",
    "        self.bart_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        # Tokenize hate speech\n",
    "        hate_inputs = self.tokenizer(\n",
    "            row[\"hatespeech\"],\n",
    "            return_tensors='pt',\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "        # Tokenize counterspeech\n",
    "        counter_inputs = self.bart_tokenizer(\n",
    "            row[\"counterspeech\"],\n",
    "            return_tensors='pt',\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "        # Define intent categories\n",
    "        categories = {\n",
    "            'informative': 0,\n",
    "            'questioning': 1,\n",
    "            'denouncing': 2,\n",
    "            'positive': 3,\n",
    "            'humor': 4\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            'input_ids': hate_inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': hate_inputs['attention_mask'].squeeze(0),\n",
    "            'counter_speech': counter_inputs['input_ids'].squeeze(0),\n",
    "            'intent_id': torch.tensor(categories[row[\"csType\"].lower()], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DjDAavD0_6dX",
    "outputId": "4fa0dee1-8852-4c22-dc9d-69e7432beafc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9532\n",
      "2971\n",
      "1470\n",
      "{'input_ids': tensor([  101,  2672,  1996,  4895,  2071,  2831,  2000,  2216,  4004,  1998,\n",
      "         3060,  3741,  3625,  2005,  3938,  1009,  1997,  1996, 10796,  1999,\n",
      "         1996, 17401,  2612,  1997, 22604,  2006,  2023, 14636,  2055,  4785,\n",
      "         2689,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'counter_speech': tensor([    0,   133,   201,    16,     5,   200,   144,  2902, 15024,   247,\n",
      "           11,     5,   232,   111,    25,     5,   232,    17,    27,    29,\n",
      "          934,  2683,     8,  1861,   476,     4,    52,    32,    70,     7,\n",
      "         4887,   259,     8,   240,     7,   173,   865,    11,   865,     7,\n",
      "         1045,  5068,   464,     6,    25,  4340,     7,  7547,     5,  8411,\n",
      "            7,   643,     4,     2,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1]), 'intent_id': tensor(0)}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DialoGPTDataset(training_data)\n",
    "test_dataset = DialoGPTDataset(testing_data)\n",
    "validation_dataset = DialoGPTDataset(validation_data)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(validation_dataset))\n",
    "\n",
    "print(train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LpupYCINMIin"
   },
   "outputs": [],
   "source": [
    "class FeatureEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, next_input):\n",
    "        super(FeatureEncoder, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained('GroNLP/hateBERT')\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_size = next_input\n",
    "\n",
    "        self.informative_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.questioning_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.denouncing_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.positive_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.humor_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.output_size),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hate_speech_h = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        informative_e = self.informative_head(hate_speech_h)\n",
    "        questioning_e = self.questioning_head(hate_speech_h)\n",
    "        denouncing_e = self.denouncing_head(hate_speech_h)\n",
    "        positive_e = self.positive_head(hate_speech_h)\n",
    "        humor_e = self.humor_head(hate_speech_h)\n",
    "\n",
    "        return informative_e, questioning_e, denouncing_e, positive_e, humor_e, hate_speech_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyXBzACbO4b6",
    "outputId": "5652bd54-a540-4980-bde6-8b0ddd5e8599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.0000, 0.0000, 0.0000, 0.1041, 0.1391, 0.2064, 0.0000, 0.0000, 0.1552,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.4886, 0.1636, 0.0000, 0.0000, 0.0977,\n",
      "         0.0000, 0.2259, 0.0000, 0.0000, 0.3120, 0.2144, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0521, 0.0000, 0.1998, 0.0000, 0.0000, 0.0322, 0.1853, 0.0669,\n",
      "         0.0000, 0.0000, 0.0000, 0.3507, 0.0000, 0.0000, 0.0000, 0.2598, 0.1648,\n",
      "         0.0390, 0.0288, 0.0000, 0.0000, 0.0000, 0.0000, 0.3204, 0.0173, 0.0625,\n",
      "         0.0778, 0.7104, 0.0812, 0.1457, 0.3830, 0.0000, 0.1012, 0.1235, 0.0260,\n",
      "         0.0000, 0.2348, 0.0000, 0.1559, 0.0000, 0.1859, 0.3386, 0.0000, 0.0000,\n",
      "         0.5267, 0.0749, 0.2583, 0.3908, 0.0000, 0.0000, 0.0000, 0.4191, 0.0000,\n",
      "         0.0000, 0.4671, 0.0000, 0.0000, 0.0653, 0.3277, 0.0000, 0.1911, 0.0000,\n",
      "         0.3217, 0.3876, 0.0279, 0.0799, 0.0922, 0.0929, 0.0000, 0.1722, 0.0000,\n",
      "         0.3725]], grad_fn=<ReluBackward0>), tensor([[0.1835, 0.1692, 0.0791, 0.0622, 0.3001, 0.0000, 0.0000, 0.0174, 0.0821,\n",
      "         0.0000, 0.2966, 0.3389, 0.3730, 0.0016, 0.0000, 0.0737, 0.3387, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0572, 0.0000, 0.0000, 0.0000, 0.0085,\n",
      "         0.0381, 0.0000, 0.0000, 0.0000, 0.0000, 0.2260, 0.0000, 0.0584, 0.0000,\n",
      "         0.2361, 0.0000, 0.4562, 0.0000, 0.0000, 0.0841, 0.0000, 0.1277, 0.1955,\n",
      "         0.0000, 0.0000, 0.2514, 0.1943, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2056, 0.0000, 0.4594, 0.0000, 0.2482, 0.0000, 0.1056, 0.0000, 0.0255,\n",
      "         0.3380, 0.0482, 0.0000, 0.3127, 0.0579, 0.0000, 0.5349, 0.4083, 0.0733,\n",
      "         0.1240, 0.2549, 0.1973, 0.0000, 0.0238, 0.0000, 0.4357, 0.4446, 0.0000,\n",
      "         0.0180, 0.4711, 0.0000, 0.0000, 0.0000, 0.0000, 0.4341, 0.0000, 0.4099,\n",
      "         0.2349, 0.6237, 0.0000, 0.0000, 0.1513, 0.0227, 0.0000, 0.0000, 0.0000,\n",
      "         0.0904]], grad_fn=<ReluBackward0>), tensor([[0.0000e+00, 9.0066e-02, 6.8435e-02, 0.0000e+00, 8.8109e-02, 0.0000e+00,\n",
      "         0.0000e+00, 2.7146e-01, 5.2978e-01, 0.0000e+00, 0.0000e+00, 4.1468e-01,\n",
      "         2.0227e-01, 2.7400e-01, 4.4502e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.4033e-01, 0.0000e+00, 0.0000e+00, 2.4694e-01, 1.9776e-01,\n",
      "         0.0000e+00, 0.0000e+00, 3.8405e-01, 1.4052e-01, 5.5147e-02, 4.8096e-01,\n",
      "         3.8212e-02, 7.1269e-02, 0.0000e+00, 1.5848e-04, 0.0000e+00, 7.7676e-02,\n",
      "         0.0000e+00, 8.2275e-02, 4.8731e-01, 1.8772e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.9050e-02, 0.0000e+00, 2.0101e-01, 7.5524e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8586e-02, 3.2655e-01, 7.1824e-02,\n",
      "         0.0000e+00, 0.0000e+00, 3.2462e-01, 6.4895e-02, 0.0000e+00, 0.0000e+00,\n",
      "         4.4838e-01, 6.8277e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.9067e-02, 0.0000e+00, 0.0000e+00, 6.2016e-01, 2.3266e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.2017e-01, 2.1555e-01, 0.0000e+00, 0.0000e+00,\n",
      "         2.6131e-01, 3.0905e-01, 0.0000e+00, 4.5224e-03, 4.5760e-01, 2.8011e-01,\n",
      "         0.0000e+00, 3.5735e-01, 0.0000e+00, 2.8719e-02, 0.0000e+00, 2.9433e-01,\n",
      "         0.0000e+00, 0.0000e+00, 5.9984e-01, 3.8284e-01, 4.9469e-01, 1.1318e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7458e-01]],\n",
      "       grad_fn=<ReluBackward0>), tensor([[0.0000, 0.4813, 0.0504, 0.3679, 0.0000, 0.1607, 0.1960, 0.0000, 0.0000,\n",
      "         0.6048, 0.0000, 0.0821, 0.0000, 0.0000, 0.0000, 0.3238, 0.3491, 0.1017,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1826, 0.0868, 0.1182, 0.0000, 0.0000,\n",
      "         0.0000, 0.2105, 0.0000, 0.0000, 0.0000, 0.1028, 0.0000, 0.1504, 0.0000,\n",
      "         0.2538, 0.5241, 0.0000, 0.0000, 0.0000, 0.1963, 0.0000, 0.0000, 0.0000,\n",
      "         0.5310, 0.0000, 0.1088, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4652, 0.0813, 0.0758, 0.0000, 0.0000, 0.0000, 0.3681,\n",
      "         0.1734, 0.0000, 0.1259, 0.0000, 0.0000, 0.0000, 0.5743, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.3318, 0.0000, 0.3209, 0.0000, 0.0000, 0.6810, 0.0591,\n",
      "         0.0000, 0.0165, 0.0000, 0.6073, 0.0000, 0.0000, 0.0824, 0.0000, 0.0523,\n",
      "         0.0000, 0.3310, 0.0000, 0.0000, 0.0000, 0.0728, 0.0000, 0.1294, 0.0000,\n",
      "         0.0000]], grad_fn=<ReluBackward0>), tensor([[0.0000, 0.0000, 0.0000, 0.3980, 0.0395, 0.0000, 0.3816, 0.3791, 0.2627,\n",
      "         0.5853, 0.1773, 0.0000, 0.3165, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4063, 0.4097, 0.3685, 0.2249, 0.0000, 0.2847, 0.0000,\n",
      "         0.1391, 0.5120, 0.0000, 0.0000, 0.0000, 0.0000, 0.1785, 0.0000, 0.0000,\n",
      "         0.0000, 0.1570, 0.0270, 0.2766, 0.0950, 0.0126, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1526, 0.0000, 0.2106, 0.0203,\n",
      "         0.5458, 0.4070, 0.4994, 0.0447, 0.0000, 0.3981, 0.0000, 0.0000, 0.0570,\n",
      "         0.1133, 0.0211, 0.1519, 0.1511, 0.0000, 0.0906, 0.0230, 0.0000, 0.1441,\n",
      "         0.0000, 0.3592, 0.3184, 0.0000, 0.0363, 0.0000, 0.0000, 0.0000, 0.1398,\n",
      "         0.1807, 0.0000, 0.0647, 0.0000, 0.0000, 0.0000, 0.3734, 0.0000, 0.1115,\n",
      "         0.0000, 0.0000, 0.1370, 0.0000, 0.8400, 0.0000, 0.2544, 0.0000, 0.0000,\n",
      "         0.2476]], grad_fn=<ReluBackward0>), tensor([[-1.2317e-01,  2.5760e-01, -6.8412e-01,  4.6821e-01,  8.0943e-01,\n",
      "         -2.5792e-01,  1.5351e-01,  1.3639e+00, -1.0266e+00,  1.3265e-01,\n",
      "         -6.1926e-01,  2.1133e-01, -4.9460e-01,  7.6190e-01, -6.9545e-02,\n",
      "          6.8312e-01,  3.7021e-01, -4.6095e-01,  3.3195e-01,  5.0576e-01,\n",
      "          2.4192e-01, -2.2491e-01,  3.1872e-01,  8.5852e-01,  1.3688e-01,\n",
      "         -4.0543e-01,  5.2988e-01,  7.3655e-01, -1.8011e-01,  4.7114e-01,\n",
      "          1.1463e-01, -1.9435e-01,  3.9097e-02, -1.4291e-01, -1.6129e-01,\n",
      "         -4.2231e-01, -7.1753e-01,  2.2965e-01, -1.0829e-01,  4.8140e-01,\n",
      "         -2.8108e-01,  3.4257e-02, -2.7372e-01, -4.2401e-01,  1.7613e-01,\n",
      "          5.1272e-01, -1.1607e+00,  9.1711e-01,  4.1866e-01,  1.1515e-01,\n",
      "          2.4045e-02,  4.7473e-01,  5.9433e-01, -1.7153e-01,  1.6978e-01,\n",
      "          6.4695e-01, -4.9544e-01,  4.1428e-02, -1.0952e+00,  3.7566e-03,\n",
      "          2.9936e-01, -5.2084e-01, -4.3595e-02,  3.3521e-01,  1.2925e-01,\n",
      "          2.1945e-01,  1.5714e-01, -5.9910e-01, -3.5057e-02,  4.0079e-01,\n",
      "         -9.8173e-02,  3.8298e-01, -7.9815e-01, -6.8081e-02, -5.0185e-01,\n",
      "         -1.1499e+00,  4.8555e-01,  5.9444e-01, -1.9008e-01,  2.0195e-01,\n",
      "         -2.1091e-01, -7.6863e-02, -9.0526e-01,  4.3959e-01, -4.6773e-01,\n",
      "         -1.8348e-01,  6.2463e-02,  1.1052e+00, -3.8372e-01,  1.5440e-01,\n",
      "         -2.4588e-01,  3.0191e-01,  3.5213e-01, -1.3883e-01,  1.1457e+00,\n",
      "         -4.6540e-01,  3.4221e-01,  2.6335e-01,  5.6252e-01,  4.1568e-01,\n",
      "         -7.6780e-01, -1.1107e+00,  4.1170e-01,  4.5548e-01, -5.5886e-01,\n",
      "         -6.0578e-01, -6.8058e-01, -3.3178e-01, -2.8615e-01, -1.0600e+00,\n",
      "          1.1757e+00, -1.6308e-01,  3.4663e-01, -6.9612e-01,  1.6039e-01,\n",
      "          6.7695e-01,  6.8573e-01, -4.1015e-01, -1.3529e-01,  3.5348e-01,\n",
      "          3.2437e-01,  2.6495e-01, -3.6576e-03, -7.7232e-02, -4.1760e-01,\n",
      "          1.2196e-01,  4.7131e-01, -1.5215e-01, -3.7126e-01, -1.7947e-01,\n",
      "          4.6674e-01,  7.4275e-01,  4.2055e-01, -3.5353e-01,  4.1961e-01,\n",
      "         -1.3581e-01,  1.5983e-01, -4.0132e-01,  1.1101e+00, -1.9269e-01,\n",
      "          6.2207e-01, -2.3745e-01, -1.8398e+00,  2.3780e-01,  9.0787e-02,\n",
      "          6.5546e-01, -3.2986e-01, -1.7356e-01, -1.8928e-01,  7.1867e-01,\n",
      "         -1.2658e-01,  6.1733e-02,  1.8678e-01, -3.1777e-01, -5.4623e-01,\n",
      "         -2.5240e-01, -4.4977e-01, -3.9046e-02,  7.4262e-01, -5.8837e-02,\n",
      "          1.6054e-01, -5.0865e-01,  1.7492e-01, -2.7634e-01,  1.2887e-01,\n",
      "          8.1764e-02,  5.0241e-02,  9.8645e-01, -4.3364e-01,  1.4911e-01,\n",
      "         -5.8697e-01, -6.5167e-01,  9.5687e-01, -1.8770e-01,  4.1894e-01,\n",
      "         -3.7152e-01,  6.5440e-01,  4.5212e-01, -8.6196e-02, -2.2374e-01,\n",
      "         -8.7534e-01,  2.2465e-01, -2.1325e-01,  6.3038e-01,  1.1065e-01,\n",
      "         -5.4311e-01, -5.1110e-02,  5.6019e-01,  1.1177e+00, -3.2925e-01,\n",
      "         -5.6906e-01,  1.7327e-01,  6.8197e-02,  3.8716e-01, -5.0439e-02,\n",
      "         -2.0217e-01,  1.4270e-01,  7.4871e-01,  2.7728e-01,  1.7624e-01,\n",
      "         -9.2496e-01,  2.3841e-01,  6.4823e-01, -4.1757e-01, -6.7736e-01,\n",
      "          2.4559e+00, -1.8675e-01,  1.0047e-01,  1.5118e-01,  5.0533e-01,\n",
      "         -4.2134e-01, -8.7620e-04, -4.5003e-02,  1.6084e-01, -6.0728e-01,\n",
      "          1.9793e-01, -7.8367e-01,  2.2306e-01, -2.2293e-01,  2.4963e-01,\n",
      "          6.9048e-01,  6.4160e-01, -1.2937e-01,  7.0448e-02, -5.7323e-02,\n",
      "          4.0691e-01,  5.9287e-01, -5.5968e-02,  8.0828e-01, -2.3386e-01,\n",
      "         -5.2182e-01, -3.5160e-01,  3.1023e-02, -1.1959e-01,  2.9239e-02,\n",
      "          1.0504e-01, -1.4949e-01,  1.1976e-01,  8.0820e-01,  8.3419e-02,\n",
      "         -3.6125e-01, -2.9663e-01, -6.0953e-01,  5.0977e-01,  4.5629e-01,\n",
      "          4.5553e-01,  5.1052e-01,  2.2577e-01, -3.3124e-01,  4.3715e-01,\n",
      "         -3.4963e-01,  3.9342e-01, -1.8830e-03, -3.4032e-01,  1.5296e-01,\n",
      "          8.7104e-02, -1.6105e-01,  5.3819e-01,  2.1507e-01, -6.3888e-01,\n",
      "         -7.4827e-02,  5.1826e-03, -1.8684e-01,  5.4644e-02, -2.3305e-01,\n",
      "         -7.6733e-01,  7.9099e-01,  9.4913e-02,  6.2855e-01,  1.3569e-01,\n",
      "          3.5545e-01,  6.2363e-01,  4.5773e-02, -1.6890e+00, -2.3884e-02,\n",
      "         -5.0119e-01,  1.3611e-01,  4.0873e-01, -1.5019e-01,  5.2313e-01,\n",
      "          6.4430e-01,  1.1717e+00, -9.5832e-01, -6.1409e-01, -8.0561e-01,\n",
      "         -1.6220e-01,  2.4920e-01, -8.2227e-01, -4.3588e-02, -2.6612e-02,\n",
      "          3.4783e-01, -7.0667e-01, -2.0241e-01, -9.8403e-01, -2.2646e-02,\n",
      "          2.2685e-01,  1.3894e-01, -6.7778e-01,  6.9484e-01, -5.4873e-02,\n",
      "         -6.6487e-02, -5.5729e-01,  3.6755e-02,  2.2070e-02, -7.1231e-01,\n",
      "          2.7916e-01, -4.7228e-04, -8.7007e-01, -3.1925e+00, -3.8667e-01,\n",
      "          1.9817e-01,  6.7628e-01, -1.0927e-01,  1.7100e-01,  2.4088e-01,\n",
      "          7.8297e-02, -4.5646e-01,  1.0410e-01,  3.8411e-01,  5.1960e-01,\n",
      "          9.7735e-02, -5.6284e-01,  4.5912e-01,  2.0076e-01,  3.5869e-01,\n",
      "         -2.8795e-03,  3.4292e-01,  4.7845e-01, -5.0375e-02, -1.2040e-01,\n",
      "         -2.4911e-01,  2.2337e-01,  4.4491e-01,  2.2470e-01,  2.1969e-01,\n",
      "         -7.0901e-01, -7.5797e-02, -4.0109e-01,  2.1902e-01, -3.0490e-01,\n",
      "         -1.5279e-01, -1.9591e-01,  3.9023e-01,  3.0864e-01, -9.3815e-02,\n",
      "          5.2041e-01, -2.5760e-01,  3.0921e-01, -2.5657e-01, -6.5282e-01,\n",
      "         -4.6588e-02, -3.0058e-01,  9.0686e-01, -1.7764e-01, -1.2411e-01,\n",
      "         -8.6077e-01,  2.9516e-01,  4.3452e-01,  2.8654e-01,  5.3828e-01,\n",
      "          8.1635e-01, -3.2586e-01, -2.4166e-01, -2.7436e-01,  7.0768e-01,\n",
      "          1.5937e-01, -2.4538e-01,  1.2337e-01,  1.3415e-01,  4.9002e-01,\n",
      "          3.2754e-01,  2.2374e-02, -1.3236e-01, -5.5545e-02, -2.2924e-01,\n",
      "         -5.6747e-01,  1.2857e-01, -2.7168e-01, -9.6040e-01,  3.1013e-01,\n",
      "         -5.3072e-01, -1.0119e+00, -2.3787e-01, -1.0075e+00, -4.9160e-01,\n",
      "         -3.0076e-01, -1.0902e-01,  2.2922e-02, -6.6215e-01, -2.1729e-01,\n",
      "         -1.3537e-01,  8.3462e-01,  5.5448e-01, -1.3850e-01, -4.5189e-01,\n",
      "         -3.4199e-01,  5.7501e-02, -3.8554e-02,  4.5402e-01, -9.7354e-01,\n",
      "         -2.1974e-01,  5.9555e-02,  8.3421e-01, -6.1270e-02,  2.3983e-01,\n",
      "         -6.1180e-01,  2.1610e-01, -5.2339e-01, -4.2720e-01, -6.3771e-01,\n",
      "         -6.5095e-01, -7.1220e-01,  3.3096e-01, -2.3564e-01, -1.2212e-01,\n",
      "          9.8597e-01, -2.9605e-02,  1.9035e-01,  4.4752e-01, -7.2772e-01,\n",
      "          1.5666e-01, -2.6520e-01,  7.5874e-01,  2.2994e-01, -8.1482e-02,\n",
      "          4.4986e-01,  2.9370e-02,  3.9530e-01,  1.3770e-01,  9.5294e-01,\n",
      "         -5.7926e-02, -2.3266e-01, -3.7861e-02, -4.3921e-01, -2.4357e-01,\n",
      "         -4.3165e-01, -7.9695e-02, -6.7831e-01, -2.0219e-01,  4.1504e-02,\n",
      "          1.5968e-01, -4.6000e-02,  6.7886e-01, -3.3935e-01, -1.3622e-01,\n",
      "         -7.7347e-01, -2.9268e-02,  4.9231e-01, -6.4105e-01,  8.3318e-02,\n",
      "          4.7684e-01, -4.7184e-01, -3.9823e-01,  6.0697e-01, -5.7826e-01,\n",
      "          2.1868e-01,  3.8097e-01, -2.8612e-03, -4.8541e-01, -1.0757e+00,\n",
      "         -7.1333e-01,  4.5390e-01, -2.0179e-01,  4.3082e-01,  9.3196e-01,\n",
      "          2.4342e-01, -8.4648e-02, -1.6379e-01, -2.6147e-01,  1.8407e-01,\n",
      "         -8.2096e-01,  6.0947e-02,  5.6156e-01,  8.4814e-01, -5.1333e-01,\n",
      "         -4.9439e-01,  2.7934e-01,  4.8919e-02,  1.4163e-01, -2.6337e-01,\n",
      "         -3.5863e-01, -2.6333e-01, -4.0775e-01, -1.9226e-01, -1.3126e-01,\n",
      "         -4.9541e-02, -2.3981e-01,  8.2045e-01, -3.0229e-03, -4.5013e-01,\n",
      "         -1.8484e-01,  2.3027e-01,  3.3701e-01, -1.0127e-01, -3.4452e-01,\n",
      "         -1.9135e-01, -2.0341e-01,  3.9551e-01,  3.9827e-01,  5.0469e-01,\n",
      "         -1.2788e-01,  6.4177e-01, -6.9860e-01, -2.0280e-01,  1.3127e-01,\n",
      "          2.2284e-01, -3.1996e-01,  2.2150e-01,  1.7712e-01,  2.1998e-01,\n",
      "         -7.3683e-01,  5.1713e-01,  3.6159e-02, -3.6509e-01, -4.3328e-01,\n",
      "         -1.2380e-01,  1.8382e-01,  4.6504e-01, -9.2250e-01, -2.0718e-01,\n",
      "         -2.3360e-01,  2.2939e-01,  6.6333e-01, -6.3954e-01,  5.7905e-02,\n",
      "         -3.3022e-01,  2.4985e-02, -2.6652e-01, -1.8399e-01,  4.3828e-01,\n",
      "          4.8261e-01, -4.4609e-01,  8.0297e-01,  1.0476e-01, -1.1147e+00,\n",
      "         -3.6112e-06, -3.2108e-01, -2.2974e-01, -5.5197e-01, -9.1232e-01,\n",
      "          1.5148e-01,  6.9941e-01, -5.7468e-02, -2.8318e-01, -3.0531e-01,\n",
      "          7.6689e-02, -2.6689e-01, -4.4704e-01,  4.7444e-01,  4.6342e-02,\n",
      "         -3.6947e-01, -7.6067e-01, -7.5091e-01,  5.0563e-01, -6.5453e-01,\n",
      "          4.0746e-01,  2.8565e-01, -2.2232e-01, -6.4757e-01, -5.3656e-01,\n",
      "         -1.3978e-03, -1.0704e+00,  5.3240e-01, -2.9782e-01, -5.0650e-01,\n",
      "         -4.1498e-02, -4.4396e-01,  2.0083e-02,  1.7154e-01, -3.1965e-02,\n",
      "         -6.9168e-01, -4.4352e-01,  8.8167e-01, -2.6560e-01, -5.4387e-01,\n",
      "         -3.6767e-01,  3.1593e-01, -1.7683e-01,  2.3699e-01, -9.4361e-02,\n",
      "         -1.5392e-01, -4.3483e-02,  4.9739e-01,  8.1368e-02, -6.3719e-03,\n",
      "         -2.6060e-01,  1.0677e+00, -1.2285e+00,  1.0485e+00,  1.0843e+00,\n",
      "         -2.1918e-01, -1.6651e-01, -8.3577e-03, -1.3463e-01, -1.6047e-01,\n",
      "          9.8834e-02,  6.2214e-01, -2.0275e-01,  2.0175e-01, -3.1997e-01,\n",
      "         -4.9679e-01,  3.3211e-01,  3.8114e-01,  5.7119e-01,  5.1291e-01,\n",
      "          1.8488e-02, -4.2402e-01,  1.7790e-01, -1.1871e+00, -2.0845e-01,\n",
      "         -3.9290e-02,  5.5680e-01,  8.9255e-01, -5.8632e-02,  3.3880e-01,\n",
      "          9.5283e-02,  9.5194e-03, -2.3480e-02, -1.6059e-01,  3.4324e-01,\n",
      "          3.7971e-02,  2.7206e-01,  1.3271e-01,  3.6109e-01,  2.9792e-01,\n",
      "          5.6152e-01,  7.6749e-01, -4.0285e-02, -1.6407e-01, -6.9849e-01,\n",
      "         -5.7901e-01,  7.9291e-01,  9.6178e-02,  8.0835e-03, -6.0179e-01,\n",
      "         -2.1675e-01,  1.0679e-01,  9.2902e-01,  3.8888e-01,  1.2707e+00,\n",
      "          2.8934e-01, -7.8272e-01, -5.9534e-01,  1.0079e+00,  1.8520e-01,\n",
      "         -5.8274e-01, -7.6067e-01,  9.1246e-01,  7.4106e-01,  3.6579e-01,\n",
      "          2.6696e-01,  3.0449e-01,  4.0488e-01, -4.7377e-02, -4.9712e-01,\n",
      "          3.2128e-01,  7.3942e-02, -2.2706e-01, -4.1623e-02, -4.0169e-01,\n",
      "         -6.9343e-02, -6.2744e-02,  4.8091e-01,  2.4996e-01,  2.6361e-01,\n",
      "          1.2227e-01,  8.5500e-01, -1.2661e+00, -1.7783e-01, -5.6633e-02,\n",
      "          8.3859e-01,  1.1827e-01,  4.8322e-01,  4.5807e-01, -1.1281e-02,\n",
      "         -5.8511e-02,  3.8427e-01, -5.6437e-03,  1.6789e-01,  1.0114e-01,\n",
      "          1.1220e-01, -5.1211e-01,  8.3886e-01, -2.4258e-01, -8.4999e-01,\n",
      "         -4.9027e-01,  3.7390e-01,  4.1485e-01, -3.3120e-01,  9.7744e-01,\n",
      "         -4.5607e-01, -7.3515e-03, -7.3092e-02,  8.7236e-02, -3.0596e-01,\n",
      "          4.6145e-01,  1.8278e-01,  1.9414e-01,  5.5773e-01, -6.4275e-01,\n",
      "         -4.8545e-01,  5.0916e-01, -5.0577e-01, -9.8773e-01,  3.9029e-01,\n",
      "         -7.1127e-02,  1.7022e-01, -6.7253e-01,  7.6379e-01,  1.0064e-01,\n",
      "         -1.7974e-01,  2.8179e-01, -2.8583e-02, -5.7483e-01, -2.1858e-01,\n",
      "          3.5220e-01,  2.2009e-02,  1.3801e-01,  1.1380e+00,  3.3350e-02,\n",
      "         -1.3364e-01,  3.1937e-01, -6.0456e-01,  4.3839e-01,  1.6217e-02,\n",
      "          2.9566e-01,  4.8918e-01, -3.1255e-01,  3.8324e-01, -7.4790e-01,\n",
      "         -6.5821e-01,  5.5319e-01,  1.8778e-01, -4.6856e-01, -8.2878e-02,\n",
      "         -1.4972e-02, -5.5359e-01,  7.8357e-01, -6.4829e-01,  2.1436e-03,\n",
      "          2.2975e-01,  3.1753e-02, -5.4749e-01, -1.0020e+00, -8.0302e-02,\n",
      "          3.9623e-02, -5.9870e-02, -3.5461e-01, -3.1486e-02,  1.2653e-01,\n",
      "         -2.3913e-01,  3.7739e-01, -3.7753e+00, -9.8182e-01, -2.3795e-01,\n",
      "         -8.2952e-01, -5.5751e-01,  2.5009e-01,  7.1639e-01, -4.8086e-01,\n",
      "         -1.4179e-02, -1.4914e-01, -1.1136e-01, -2.0262e-01,  1.9009e-02,\n",
      "         -7.5536e-01,  5.8692e-01,  2.5884e-01]], grad_fn=<SliceBackward0>))\n"
     ]
    }
   ],
   "source": [
    "feature_encoder = FeatureEncoder(input_dim=128, hidden_dim=768, next_input=100)\n",
    "print(feature_encoder(train_dataset[0]['input_ids'].unsqueeze(0), train_dataset[0]['attention_mask'].unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8qxFuKQrRtuO"
   },
   "outputs": [],
   "source": [
    "class CounterSpeechNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, encoder_output, max_length):\n",
    "        super(CounterSpeechNetwork, self).__init__()\n",
    "\n",
    "        self.feature_encoder = FeatureEncoder(input_dim, hidden_dim, encoder_output)\n",
    "\n",
    "        self.informative_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "        self.questioning_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "        self.denouncing_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "        self.positive_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "        self.humor_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "\n",
    "        self.informative_fusion = torch.nn.Linear(hidden_dim + encoder_output, self.informative_decoder.config.d_model)\n",
    "        self.questioning_fusion = torch.nn.Linear(hidden_dim + encoder_output, self.questioning_decoder.config.d_model)\n",
    "        self.denouncing_fusion = torch.nn.Linear(hidden_dim + encoder_output, self.denouncing_decoder.config.d_model)\n",
    "        self.positive_fusion = torch.nn.Linear(hidden_dim + encoder_output, self.positive_decoder.config.d_model)\n",
    "        self.humor_fusion = torch.nn.Linear(hidden_dim + encoder_output, self.humor_decoder.config.d_model)\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, intent_id, counter_speech=None):\n",
    "        informative_e, questioning_e, denouncing_e, positive_e, humor_e, hate_speech_h = self.feature_encoder(input_ids, attention_mask)\n",
    "\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        fused = torch.zeros(batch_size, 1, self.informative_decoder.config.d_model, device=input_ids.device)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            if intent_id[i] == 0:\n",
    "                fused[i] = self.informative_fusion(torch.cat((hate_speech_h[i], informative_e[i]), dim=-1)).unsqueeze(0)\n",
    "            elif intent_id[i] == 1:\n",
    "                fused[i] = self.questioning_fusion(torch.cat((hate_speech_h[i], questioning_e[i]), dim=-1)).unsqueeze(0)\n",
    "            elif intent_id[i] == 2:\n",
    "                fused[i] = self.denouncing_fusion(torch.cat((hate_speech_h[i], denouncing_e[i]), dim=-1)).unsqueeze(0)\n",
    "            elif intent_id[i] == 3:\n",
    "                fused[i] = self.positive_fusion(torch.cat((hate_speech_h[i], positive_e[i]), dim=-1)).unsqueeze(0)\n",
    "            elif intent_id[i] == 4:\n",
    "                fused[i] = self.humor_fusion(torch.cat((hate_speech_h[i], humor_e[i]), dim=-1)).unsqueeze(0)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid intent_id: {intent_id[i]}\")\n",
    "\n",
    "        if counter_speech is not None:\n",
    "            losses = []\n",
    "            for i in range(batch_size):\n",
    "                if intent_id[i] == 0:\n",
    "                    output = self.informative_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
    "                elif intent_id[i] == 1:\n",
    "                    output = self.questioning_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
    "                elif intent_id[i] == 2:\n",
    "                    output = self.denouncing_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
    "                elif intent_id[i] == 3:\n",
    "                    output = self.positive_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
    "                elif intent_id[i] == 4:\n",
    "                    output = self.humor_decoder(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), labels=counter_speech[i].unsqueeze(0))\n",
    "                losses.append(output.loss)\n",
    "            avg_loss = sum(losses) / len(losses)  # Average loss across the batch\n",
    "            return None, avg_loss  # No decoded text during training\n",
    "        else:\n",
    "            decoded_texts = []\n",
    "            for i in range(batch_size):\n",
    "                if intent_id[i] == 0:\n",
    "                    output = self.informative_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
    "                elif intent_id[i] == 1:\n",
    "                    output = self.questioning_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
    "                elif intent_id[i] == 2:\n",
    "                    output = self.denouncing_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
    "                elif intent_id[i] == 3:\n",
    "                    output = self.positive_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
    "                elif intent_id[i] == 4:\n",
    "                    output = self.humor_decoder.generate(encoder_outputs=BaseModelOutput(last_hidden_state=fused[i].unsqueeze(0)), max_length=self.max_length, num_beams=4, early_stopping=True)\n",
    "                decoded_texts.append(self.tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "            return decoded_texts, None  # Decoded text during inference, no loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dVxqr6WWc8j",
    "outputId": "1bf35674-29e9-4ad9-b9a1-65898292fc9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, tensor(15.3572, grad_fn=<DivBackward0>))\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "counterspeechnetwork = CounterSpeechNetwork(input_dim=128, hidden_dim=768, encoder_output=256, max_length=50)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    input_ids = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    intent_id = batch['intent_id']\n",
    "    counter_speech = batch['counter_speech']\n",
    "\n",
    "    print(counterspeechnetwork(input_ids, attention_mask, intent_id, counter_speech))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "du_G6NX9c_MN",
    "outputId": "01eb8d9f-36ee-4632-a7ff-bb39026481cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 2.1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Validation Loss: 0.7590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.8208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Validation Loss: 0.7166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.7238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Validation Loss: 0.7017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.6653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Validation Loss: 0.6874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.6188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Validation Loss: 0.6816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Validation Loss: 0.6832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.5316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Validation Loss: 0.6904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.4892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Validation Loss: 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.4509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Validation Loss: 0.7109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.4156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Validation Loss: 0.7229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model = CounterSpeechNetwork(input_dim=128, hidden_dim=768, encoder_output=256, max_length=50)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "\n",
    "    # Wrap train_dataloader with tqdm for training progress\n",
    "    train_loop = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs} [Train]\", leave=False)\n",
    "    for batch in train_loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        counter_speech = batch['counter_speech'].to(device)\n",
    "        intent_ids = batch['intent_id'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Process the entire batch at once\n",
    "        _, loss = model(input_ids, attention_mask, intent_ids, counter_speech)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Update tqdm with current batch loss\n",
    "        train_loop.set_postfix({'batch_loss': loss.item(), 'avg_loss': total_train_loss / (train_loop.n + 1)})\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} | Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    # Wrap validation_dataloader with tqdm for validation progress\n",
    "    val_loop = tqdm(validation_dataloader, desc=f\"Epoch {epoch + 1}/{epochs} [Validation]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loop:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            counter_speech = batch['counter_speech'].to(device)\n",
    "            intent_ids = batch['intent_id'].to(device)\n",
    "\n",
    "            # Process the entire batch at once\n",
    "            _, loss = model(input_ids, attention_mask, intent_ids, counter_speech)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # Update tqdm with current batch loss\n",
    "            val_loop.set_postfix({'batch_loss': loss.item(), 'avg_loss': total_val_loss / (val_loop.n + 1)})\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(validation_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} | Validation Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'architecture_parameters.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2ChcK0JiiHeC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Evaluation: 100%|██████████████████████████████████████████████████████████████████| 93/93 [09:44<00:00,  6.28s/it, predictions=2971]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2971 test predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test evaluation\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "test_references = []\n",
    "\n",
    "# Wrap test_dataloader with tqdm for test progress\n",
    "test_loop = tqdm(test_dataloader, desc=\"Test Evaluation\", leave=True)\n",
    "with torch.no_grad():\n",
    "    for batch in test_loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        counter_speech = batch['counter_speech'].to(device)  # Reference texts\n",
    "        intent_ids = batch['intent_id'].to(device)\n",
    "\n",
    "        # Generate predictions without providing counter_speech\n",
    "        predictions, _ = model(input_ids, attention_mask, intent_ids)\n",
    "\n",
    "        # Decode reference texts\n",
    "        references = [model.tokenizer.decode(cs, skip_special_tokens=True) for cs in counter_speech]\n",
    "\n",
    "        test_predictions.extend(predictions)\n",
    "        test_references.extend(references)\n",
    "\n",
    "        # Update tqdm with progress stats (e.g., number of predictions)\n",
    "        test_loop.set_postfix({'predictions': len(test_predictions)})\n",
    "\n",
    "# Final output\n",
    "print(f\"Generated {len(test_predictions)} test predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2fe5ddb0f6471ba4f6b0f9242ecb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "P, R, F1 = bert_score(test_predictions, test_references, lang=\"en\", verbose=True)\n",
    "\n",
    "# Final output\n",
    "print(f\"Generated {len(test_predictions)} test predictions\")\n",
    "print(f\"BERTScore - Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "for pred, ref in zip(test_predictions, test_references):\n",
    "    scores = scorer.score(ref, pred)  # ROUGE scores for each prediction-reference pair\n",
    "    rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n",
    "    rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n",
    "    rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n",
    "\n",
    "# Compute average ROUGE scores\n",
    "avg_rouge1 = sum(rouge_scores['rouge1']) / len(rouge_scores['rouge1'])\n",
    "avg_rouge2 = sum(rouge_scores['rouge2']) / len(rouge_scores['rouge2'])\n",
    "avg_rougeL = sum(rouge_scores['rougeL']) / len(rouge_scores['rougeL'])\n",
    "\n",
    "print(f\"ROUGE - Rouge1: {avg_rouge1:.4f}, Rouge2: {avg_rouge2:.4f}, RougeL: {avg_rougeL:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred, ref in zip(test_predictions, test_references):\n",
    "    print(f'Generated: {pred}')\n",
    "    print(f'Actual: {ref}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00606f57d8884a8da09c02a2b181667c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_baa6a137ee63491cb9a5f54e44095154",
      "max": 7021,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_13cfef767914493fb7c16b42845c4c45",
      "value": 7021
     }
    },
    "1274c2be26b64ab3b4ac358f7606a310": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13cfef767914493fb7c16b42845c4c45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "36aff3cc8ee845b08abd7f18589726fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f5df75b26d1d464fb722dff990b5476a",
       "IPY_MODEL_00606f57d8884a8da09c02a2b181667c",
       "IPY_MODEL_5ae640fb971841d9b86737e6fd0b4c78"
      ],
      "layout": "IPY_MODEL_452dc6a25a544daab3217fae74b699e9"
     }
    },
    "452dc6a25a544daab3217fae74b699e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d09db8336c340e4be9bc537537f4b0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ae640fb971841d9b86737e6fd0b4c78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95abeb3513704f59b66711a516c6130a",
      "placeholder": "​",
      "style": "IPY_MODEL_4d09db8336c340e4be9bc537537f4b0d",
      "value": " 7.02k/7.02k [00:00&lt;00:00, 436kB/s]"
     }
    },
    "95abeb3513704f59b66711a516c6130a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baa6a137ee63491cb9a5f54e44095154": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5df75b26d1d464fb722dff990b5476a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fccb872427ac46018921c52b405210ea",
      "placeholder": "​",
      "style": "IPY_MODEL_1274c2be26b64ab3b4ac358f7606a310",
      "value": "Downloading builder script: 100%"
     }
    },
    "fccb872427ac46018921c52b405210ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
